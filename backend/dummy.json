{
    "Rajanikanth Aluvalu": {
        "data": [
            {
                "source": "arxiv",
                "title": "Co/Ni multilayers for spintronics: high spin-polarization and tunable\n  magnetic anisotropy",
                "year": 2018,
                "authors": [
                    "S. Andrieu",
                    "T. Hauet",
                    "M. Gottwald",
                    "A. Rajanikanth",
                    "L. Calmels",
                    "A. M. Bataille",
                    "F. Montaigne",
                    "S. Mangin",
                    "E. Otero",
                    "P. Ohresser",
                    "P. Le Fevre",
                    "F. Bertran",
                    "A. Resta",
                    "A. Vlad",
                    "A. Coati",
                    "Y. Garreau"
                ],
                "link": "http://arxiv.org/abs/1802.02020v1",
                "abstract": "In this paper we analyze in details the electronic properties of (Co/Ni)multilayers, a model system for spintronics devices. We use magneto-opticalKerr (MOKE), spin-polarized photoemission spectroscopy (SRPES), x-ray magneticcircular dichroism (XMCD) and anomalous surface diffraction experiments toinvestigate the electronic properties and perpendicular magnetic anisotropy(PMA) in [Co(x)/Ni(y)] single-crystalline stacks grown by molecular beamepitaxy."
            },
            {
                "source": "pubmed",
                "title": "Hybrid Optimized GRU-ECNN Models for Gait Recognition with Wearable IOT Devices.",
                "year": 2022,
                "authors": [
                    "Monica KM",
                    "Parvathi R",
                    "Gayathri A",
                    "Aluvalu R",
                    "Sangeetha K",
                    "Simha Reddy CV."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/in:",
                "abstract": null
            },
            {
                "source": "pubmed",
                "title": "A novel artificial intelligence-based predictive analytics technique to detect skin cancer.",
                "year": 2023,
                "authors": [
                    "Balaji P",
                    "Hung BT",
                    "Chakrabarti P",
                    "Chakrabarti T",
                    "Elngar AA",
                    "Aluvalu R."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/37346565",
                "abstract": "One of the leading causes of death among people around the world is skin cancer. It is critical to identify and classify skin cancer early to assist patients in taking the right course of action. Additionally, melanoma, one of the main skin cancer illnesses, is curable when detected and treated at an early stage. More than 75% of fatalities worldwide are related to skin cancer. A novel Artificial Golden Eagle-based Random Forest (AGEbRF) is created in this study to predict skin cancer cells at an early stage. Dermoscopic images are used in this instance as the dataset for the system's training. Additionally, the dermoscopic image information is processed using the established AGEbRF function to identify and segment the skin cancer-affected area. Additionally, this approach is simulated using a Python program, and the current research's parameters are assessed against those of earlier studies. The results demonstrate that, compared to other models, the new research model produces better accuracy for predicting skin cancer by segmentation.              Keywords:                    Artificial intelligence; Deep learning; Machine learning; Malignant tumors; Skin cancer."
            },
            {
                "source": "pubmed",
                "title": "Diagnostic structure of visual robotic inundated systems with fuzzy clustering membership correlation.",
                "year": 2023,
                "authors": [
                    "Manoharan H",
                    "Selvarajan S",
                    "Aluvalu R",
                    "Abdelhaq M",
                    "Alsaqour R",
                    "Uddin M."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/38192458",
                "abstract": "The process of using robotic technology to examine underwater systems is still a difficult undertaking because the majority of automated activities lack network connectivity. Therefore, the suggested approach finds the main hole in undersea systems and fills it using robotic automation. In the predicted model, an analytical framework is created to operate the robot within predetermined areas while maximizing communication ranges. Additionally, a clustering algorithm with a fuzzy membership function is implemented, allowing the robots to advance in accordance with predefined clusters and arrive at their starting place within a predetermined amount of time. A cluster node is connected in each clustered region and provides the central control center with the necessary data. The weights are evenly distributed, and the designed robotic system is installed to prevent an uncontrolled operational state. Five different scenarios are used to test and validate the created model, and in each case, the proposed method is found to be superior to the current methodology in terms of range, energy, density, time periods, and total metrics of operation.              Keywords:                    Errors; Fuzzy clustering; Robot; Underwater."
            },
            {
                "source": "pubmed",
                "title": "Efficient data transmission on wireless communication through a privacy-enhanced blockchain process.",
                "year": 2023,
                "authors": [
                    "Aluvalu R",
                    "Kumaran V N S",
                    "Thirumalaisamy M",
                    "Basheer S",
                    "Ali Aldhahri E",
                    "Selvarajan S."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/37346706",
                "abstract": "In the medical era, wearables often manage and find the specific data points to check important data like resting heart rate, ECG voltage, SPO2, sleep patterns like length, interruptions, and intensity, and physical activity like kind, duration, and levels. These digital biomarkers are created mainly through passive data collection from various sensors. The critical issues with this method are time and sensitivity. We reviewed the newest wireless communication trends employed in hospitals using wearable technology and privacy and Block chain to solve this problem. Based on sensors, this wireless technology controls the data gathered from numerous locations. In this study, the wearable sensor contains data from the various departments of the system. The gradient boosting method and the hybrid microwave transmission method have been proposed to find the location and convince people. The patient health decision has been submitted to hybrid microwave transmission using gradient boosting. This will help to trace the mobile phones using the calls from the threatening person, and the data is gathered from the database while tracing. From this concern, the data analysis process is based on decision-making. They adapted the data encountered by the detailed data in the statistical modeling of the system to produce exploratory data analysis for satisfying the data from the database. Complete data is classified with a 97% outcome by removing unwanted data and making it a 98% successful data classification.              Keywords:                    Blockchain; Data management; Gradient boosting; Hybrid microwave transmission; Wireless technology."
            },
            {
                "source": "pubmed",
                "title": "A review of microscopic analysis of blood cells for disease detection with AI perspective.",
                "year": 2021,
                "authors": [
                    "Deshpande NM",
                    "Gite S",
                    "Aluvalu R."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/33981834",
                "abstract": "Background:                    Any contamination in the human body can prompt changes in blood cell morphology and various parameters of cells. The minuscule images of blood cells are examined for recognizing the contamination inside the body with an expectation of maladies and variations from the norm. Appropriate segmentation of these cells makes the detection of a disease progressively exact and vigorous. Microscopic blood cell analysis is a critical activity in the pathological analysis. It highlights the investigation of appropriate malady after exact location followed by an order of abnormalities, which assumes an essential job in the analysis of various disorders, treatment arranging, and assessment of results of treatment.              Methodology:                    A survey of different areas where microscopic imaging of blood cells is used for disease detection is done in this paper. Research papers from this area are obtained from a popular search engine, Google Scholar. The articles are searched considering the basics of blood such as its composition followed by staining of blood, that is most important and mandatory before microscopic analysis. Different methods for classification, segmentation of blood cells are reviewed. Microscopic analysis using image processing, computer vision and machine learning are the main focus of the analysis and the review here. Methodologies employed by different researchers for blood cells analysis in terms of these mentioned algorithms is the key point of review considered in the study.              Results:                    Different methodologies used for microscopic analysis of blood cells are analyzed and are compared according to different performance measures. From the extensive review the conclusion is made.              Conclusion:                    There are different machine learning and deep learning algorithms employed by researchers for segmentation of blood cell components and disease detection considering microscopic analysis. There is a scope of improvement in terms of different performance evaluation parameters. Different bio-inspired optimization algorithms can be used for improvement. Explainable AI can analyze the features of AI implemented system and will make the system more trusted and commercially suitable.              Keywords:                    Blood cell; Classifier; Disease detection; Feature extraction; Image processing; Leukemia; Microscopic images; Neural network; Red blood cell; White blood cell."
            },
            {
                "source": "pubmed",
                "title": "An improved GBSO-TAENN-based EEG signal classification model for epileptic seizure detection.",
                "year": 2024,
                "authors": [
                    "Kantipudi MVVP",
                    "Kumar NSP",
                    "Aluvalu R",
                    "Selvarajan S",
                    "Kotecha K."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/38191643",
                "abstract": "Detection and classification of epileptic seizures from the EEG signals have gained significant attention in recent decades. Among other signals, EEG signals are extensively used by medical experts for diagnosing purposes. So, most of the existing research works developed automated mechanisms for designing an EEG-based epileptic seizure detection system. Machine learning techniques are highly used for reduced time consumption, high accuracy, and optimal performance. Still, it limits by the issues of high complexity in algorithm design, increased error value, and reduced detection efficacy. Thus, the proposed work intends to develop an automated epileptic seizure detection system with an improved performance rate. Here, the Finite Linear Haar wavelet-based Filtering (FLHF) technique is used to filter the input signals and the relevant set of features are extracted from the normalized output with the help of Fractal Dimension (FD) analysis. Then, the Grasshopper Bio-Inspired Swarm Optimization (GBSO) technique is employed to select the optimal features by computing the best fitness value and the Temporal Activation Expansive Neural Network (TAENN) mechanism is used for classifying the EEG signals to determine whether normal or seizure affected. Numerous intelligence algorithms, such as preprocessing, optimization, and classification, are used in the literature to identify epileptic seizures based on EEG signals. The primary issues facing the majority of optimization approaches are reduced convergence rates and higher computational complexity. Furthermore, the problems with machine learning approaches include a significant method complexity, intricate mathematical calculations, and a decreased training speed. Therefore, the goal of the proposed work is to put into practice efficient algorithms for the recognition and categorization of epileptic seizures based on EEG signals. The combined effect of the proposed FLHF, FD, GBSO, and TAENN models might dramatically improve disease detection accuracy while decreasing complexity of system along with time consumption as compared to the prior techniques. By using the proposed methodology, the overall average epileptic seizure detection performance is increased to 99.6% with f-measure of 99% and G-mean of 98.9% values."
            },
            {
                "source": "acmdl",
                "title": "Cluster Based Ensemble Classification for Intrusion Detection System",
                "year": 2017,
                "authors": [
                    "M. A. Jabbar",
                    "Rajanikanth Aluvalu",
                    "S. Sai Satyanarayana Reddy"
                ],
                "link": "https://dl.acm.org/doi/10.1145/3055635.3056595",
                "abstract": "Network security is a challenging task, as there is a tremendous growth of network -based services and sharing of sensitive information on the network. Intrusion throws a serious risk in the network. Even though many hardening systems are developed ..."
            },
            {
                "source": "nature",
                "title": "An improved GBSO-TAENN-based EEG signal classification model for epileptic seizure detection",
                "year": 2024,
                "authors": [
                    "M. V. V. Prasad Kantipudi",
                    "N. S. Pradeep Kumar",
                    "Rajanikanth Aluvalu",
                    "Shitharth Selvarajan45",
                    "K Kotecha16 na1"
                ],
                "link": "https://www.nature.com/articles/s41598-024-51337-8",
                "abstract": "Detection and classification of epileptic seizures from the EEG signals have gained significant attention in recent decades. Among other signals, EEG signals are extensively used by medical experts for diagnosing purposes. So, most of the existing research works developed automated mechanisms for designing an EEG-based epileptic seizure detection system. Machine learning techniques are highly used for reduced time consumption, high accuracy, and optimal performance. Still, it limits by the issues of high complexity in algorithm design, increased error value, and reduced detection efficacy. Thus, the proposed work intends to develop an automated epileptic seizure detection system with an improved performance rate. Here, the Finite Linear Haar wavelet-based Filtering (FLHF) technique is used to filter the input signals and the relevant set of features are extracted from the normalized output with the help of Fractal Dimension (FD) analysis. Then, the Grasshopper Bio-Inspired Swarm Optimization (GBSO) technique is employed to select the optimal features by computing the best fitness value and the Temporal Activation Expansive Neural Network (TAENN) mechanism is used for classifying the EEG signals to determine whether normal or seizure affected. Numerous intelligence algorithms, such as preprocessing, optimization, and classification, are used in the literature to identify epileptic seizures based on EEG signals. The primary issues facing the majority of optimization approaches are reduced convergence rates and higher computational complexity. Furthermore, the problems with machine learning approaches include a significant method complexity, intricate mathematical calculations, and a decreased training speed. Therefore, the goal of the proposed work is to put into practice efficient algorithms for the recognition and categorization of epileptic seizures based on EEG signals. The combined effect of the proposed FLHF, FD, GBSO, and TAENN models might dramatically improve disease detection accuracy while decreasing complexity of system along with time consumption as compared to the prior techniques. By using the proposed methodology, the overall average epileptic seizure detection performance is increased to 99.6% with f-measure of 99% and G-mean of 98.9% values."
            },
            {
                "source": "dblp",
                "title": "Energy optimization in path arbitrary wireless sensor network.",
                "year": 2024,
                "authors": [
                    "B. Harish Goud",
                    "T. N. Shankar",
                    "Basant Sah",
                    "Rajanikanth Aluvalu"
                ],
                "link": "https://doi.org/10.1111/exsy.13282",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Clustering based EO with MRF technique for effective load balancing in cloud computing.",
                "year": 2024,
                "authors": [
                    "N. Hanuman Reddy",
                    "Amit Lathigara",
                    "Rajanikanth Aluvalu",
                    "V. Uma Maheswari 0001"
                ],
                "link": "https://doi.org/10.1108/IJPCC-01-2023-0022",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Future Food Production Prediction Using AROA Based Hybrid Deep Learning Model in Agri-Sector.",
                "year": 2023,
                "authors": [
                    "Swathi Baswaraju",
                    "V. Uma Maheswari 0001",
                    "Krishna Keerthi Chennam",
                    "Arunadevi Thirumalraj",
                    "M. V. V. Prasad Kantipudi",
                    "Rajanikanth Aluvalu"
                ],
                "link": "https://doi.org/10.1007/s44230-023-00046-y",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Residual attention network based hybrid convolution network model for lung cancer detection.",
                "year": 2023,
                "authors": [
                    "Prasanalakshmi Balaji",
                    "Rajanikanth Aluvalu",
                    "Kalpna Sagar"
                ],
                "link": "https://doi.org/10.3233/IDT-230142",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "The novel emergency hospital services for patients using digital twins.",
                "year": 2023,
                "authors": [
                    "Rajanikanth Aluvalu",
                    "Swapna Mudrakola",
                    "V. Uma Maheswari 0001",
                    "A. C. Kaladevi",
                    "M. V. S. Sandhya",
                    "Chandrasekhar Rohith Bhat"
                ],
                "link": "https://doi.org/10.1016/j.micpro.2023.104794",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Efficient data transmission on wireless communication through a privacy-enhanced blockchain process.",
                "year": 2023,
                "authors": [
                    "Rajanikanth Aluvalu",
                    "V. N. Senthil Kumaran",
                    "Manikandan Thirumalaisamy",
                    "Shajahan Basheer",
                    "Eman Ali Aldhahri",
                    "Shitharth Selvarajan"
                ],
                "link": "https://doi.org/10.7717/peerj-cs.1308",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "A novel artificial intelligence-based predictive analytics technique to detect skin cancer.",
                "year": 2023,
                "authors": [
                    "Prasanalakshmi Balaji",
                    "Bui Thanh Hung",
                    "Prasun Chakrabarti",
                    "Tulika Chakrabarti",
                    "Ahmed A. Elngar",
                    "Rajanikanth Aluvalu"
                ],
                "link": "https://doi.org/10.7717/peerj-cs.1387",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Diagnostic structure of visual robotic inundated systems with fuzzy clustering membership correlation.",
                "year": 2023,
                "authors": [
                    "Hariprasath Manoharan",
                    "Shitharth Selvarajan",
                    "Rajanikanth Aluvalu",
                    "Maha S. Abdelhaq",
                    "Raed A. Alsaqour",
                    "Mueen Uddin"
                ],
                "link": "https://doi.org/10.7717/peerj-cs.1709",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Driver Drowsiness Prediction Based on Multiple Aspects Using Image Processing Techniques.",
                "year": 2022,
                "authors": [
                    "V. Uma Maheswari 0001",
                    "Rajanikanth Aluvalu",
                    "M. V. V. Prasad Kantipudi",
                    "Krishna Keerthi Chennam",
                    "Ketan Kotecha",
                    "Jatinderkumar R. Saini"
                ],
                "link": "https://doi.org/10.1109/ACCESS.2022.3176451",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Cervical Cancer Diagnosis Using Intelligent Living Behavior of Artificial Jellyfish Optimized With Artificial Neural Network.",
                "year": 2022,
                "authors": [
                    "Devikanniga Devarajan",
                    "D. Stalin Alex",
                    "T. R. Mahesh 0001",
                    "V. Vinoth Kumar 0001",
                    "Rajanikanth Aluvalu",
                    "V. Uma Maheswari 0001",
                    "S. Shitharth"
                ],
                "link": "https://doi.org/10.1109/ACCESS.2022.3221451",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "PGWO-AVS-RDA: An intelligent optimization and clustering based load balancing model in cloud.",
                "year": 2022,
                "authors": [
                    "Raghavender Reddy Kothi Laxman",
                    "Amit Lathigara",
                    "Rajanikanth Aluvalu",
                    "Uma Maheswari Viswanadhula"
                ],
                "link": "https://doi.org/10.1002/cpe.7136",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Insights on Implications of Cognitive Computing in Leveraging Online Education Systems.",
                "year": 2022,
                "authors": [
                    "M. V. V. Prasad Kantipudi",
                    "Rajanikanth Aluvalu",
                    "V. Uma Maheswari 0001",
                    "Mahesh S. Raisinghani"
                ],
                "link": "https://doi.org/10.4018/ijopcd.302082",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Bio-Signals in Medical Applications and Challenges Using Artificial Intelligence.",
                "year": 2022,
                "authors": [
                    "Mudrakola Swapna",
                    "Uma Maheswari Viswanadhula",
                    "Rajanikanth Aluvalu",
                    "Vijayakumar Vardharajan 0001",
                    "Ketan Kotecha"
                ],
                "link": "https://doi.org/10.3390/jsan11010017",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "AI Based Emotion Detection for Textual Big Data: Techniques and Contribution.",
                "year": 2021,
                "authors": [
                    "Sheetal Kusal",
                    "Shruti Patil",
                    "Ketan Kotecha",
                    "Rajanikanth Aluvalu",
                    "Varadarajan Vijayakumar 0001"
                ],
                "link": "https://doi.org/10.3390/bdcc5030043",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Pre-Processed Tweets for Secure Capital Market Analysis Using Cloud.",
                "year": 2021,
                "authors": [
                    "Sangeeta Gupta",
                    "Rajanikanth Aluvalu"
                ],
                "link": "https://doi.org/10.4018/IJSKD.2021010101",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "A review of microscopic analysis of blood cells for disease detection with AI perspective.",
                "year": 2021,
                "authors": [
                    "Nilkanth Mukund Deshpande",
                    "Shilpa Gite",
                    "Rajanikanth Aluvalu"
                ],
                "link": "https://doi.org/10.7717/peerj-cs.460",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Twitter Based Capital Market Analysis Using Cloud Statistics.",
                "year": 2019,
                "authors": [
                    "Sangeeta Gupta",
                    "Rajanikanth Aluvalu"
                ],
                "link": "https://doi.org/10.4018/IJSKD.2019040104",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Intelligent Resource Allocation Technique For Desktop-as-a-Service in Cloud Environment.",
                "year": 2014,
                "authors": [
                    "Gandhi Kishan Bipinchandra",
                    "Rajanikanth Aluvalu",
                    "Ajay Shanker Singh"
                ],
                "link": "http://arxiv.org/abs/1404.7494",
                "abstract": "The specialty of desktop-as-a-service cloud computing is that user can access their desktop and can execute applications in virtual desktops on remote servers. Resource management and resource utilization are most significant in the area of desktop-as-a-service, cloud computing; however, handling a large amount of clients in the most efficient manner poses important challenges. Especially deciding how many clients to handle on one server, and where to execute the user applications at each time is important. This is because we have to ensure maximum resource utilization along with user data confidentiality, customer satisfaction, scalability, minimum Service level agreement (SLA) violation etc. Assigning too many users to one server leads to customer dissatisfaction, while assigning too little leads to higher investments costs. So we have taken into consideration these two situations also. We study different aspects to optimize the resource usage and customer satisfaction. Here in this paper We proposed Intelligent Resource Allocation (IRA) Technique which assures the above mentioned parameters like minimum SLA violation. For this, priorities are assigned to user requests based on their SLA Factors in order to maintain their confidentiality. The results of the paper indicate that by applying IRA Technique to the already existing overbooking mechanism will improve the performance of the system with significant reduction in SLA violation."
            },
            {
                "source": "scholar",
                "title": "RFAODE: A novel ensemble intrusion detection system",
                "year": 2017,
                "authors": [
                    "MA Jabbar",
                    "R Aluvalu"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:ZfRJV9d4-WMC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Autonomous vehicles and intelligent automation: Applications, challenges, and opportunities",
                "year": 2022,
                "authors": [
                    "G Bathla",
                    "K Bhadane",
                    "RK Singh",
                    "R Kumar",
                    "R Aluvalu",
                    "R Krishnamurthi",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:XoXfffV-tXoC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Cluster based ensemble classification for intrusion detection system",
                "year": 2017,
                "authors": [
                    "MA Jabbar",
                    "R Aluvalu",
                    "SSS Reddy"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:tKAzc9rXhukC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "AI based emotion detection for textual big data: Techniques and contribution",
                "year": 2021,
                "authors": [
                    "S Kusal",
                    "S Patil",
                    "K Kotecha",
                    "R Aluvalu",
                    "V Varadarajan"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:LI9QrySNdTsC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "The Future of Health care: Machine Learning",
                "year": 2018,
                "authors": [
                    "shirina samreen Jabbar akhil",
                    "Rajanikanth Aluvalu"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:0KyAp5RtaNEC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "A survey on access control models in cloud computing",
                "year": 2015,
                "authors": [
                    "RK Aluvalu",
                    "L Muddana"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:u-x6o8ySG0sC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "A review of microscopic analysis of blood cells for disease detection with AI perspective",
                "year": 2021,
                "authors": [
                    "NM Deshpande",
                    "S Gite",
                    "R Aluvalu"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:vbGhcppDl1QC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Bio-signals in medical applications and challenges using artificial intelligence",
                "year": 2022,
                "authors": [
                    "M Swapna",
                    "UM Viswanadhula",
                    "R Aluvalu",
                    "V Vardharajan",
                    "K Kotecha"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:SpbeaW3--B0C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Cervical cancer diagnosis using intelligent living behavior of artificial jellyfish optimized with artificial neural network",
                "year": 2022,
                "authors": [
                    "D Devarajan",
                    "DS Alex",
                    "TR Mahesh",
                    "VV Kumar",
                    "R Aluvalu",
                    "VU Maheswari",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:kh2fBNsKQNwC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Emerging ICT for Bridging the Future-Proceedings of the 49th Annual Convention of the Computer Society of India (CSI) Volume 1",
                "year": 2014,
                "authors": [
                    "SC Satapathy",
                    "A Govardhan",
                    "KS Raju",
                    "JK Mandal"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:yB1At4FlUx8C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "The novel emergency hospital services for patients using digital twins",
                "year": 2023,
                "authors": [
                    "R Aluvalu",
                    "S Mudrakola",
                    "AC Kaladevi",
                    "MVS Sandhya",
                    "CR Bhat"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:9pM33mqn1YgC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "An Authentication Model with High Security for Cloud Database",
                "year": 2021,
                "authors": [
                    "KK Chennam",
                    "R Aluvalu",
                    "S Shitharth"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:L7CI7m0gUJcC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Intrusion detection system using bayesian network and feature subset selection",
                "year": 2017,
                "authors": [
                    "MA Jabbar",
                    "R Aluvalu",
                    "SSS Reddy"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:uJ-U7cs_P_0C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Enhancing cloud security through access control models: A survey",
                "year": 2015,
                "authors": [
                    "C Langaliya",
                    "R Aluvalu"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:IjCSPb-OGe4C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Data Security in Cloud Computing Using Abe-Based Access Control",
                "year": 2021,
                "authors": [
                    "R Aluvalu",
                    "VU Maheswari",
                    "KK Chennam",
                    "S Shitharth"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:EYYDruWGBe4C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "HASBE Access Control Model with Secure Key Distribution and Efficient Domain Hierarchy for Cloud Computing.",
                "year": 2016,
                "authors": [
                    "R Aluvalu",
                    "V Kamliya",
                    "L Muddana"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:Y0pCki6q_DkC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Leaf disease classification in smart agriculture using deep neural network architecture and IoT",
                "year": 2022,
                "authors": [
                    "K Ramana",
                    "R Aluvala",
                    "MR Kumar",
                    "G Nagaraja",
                    "AV Krishna",
                    "P Nagendra"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:0N-VGjzr574C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "An efficient multilevel thresholding scheme for heart image segmentation using a hybrid generalized adversarial network",
                "year": 2022,
                "authors": [
                    "AM Reddy",
                    "KS Reddy",
                    "M Jayaram",
                    "N Venkata Maha Lakshmi",
                    "R Aluvalu",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:Ri6SYOTghG4C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Application of machine learning algorithms for facial expression analysis",
                "year": 2021,
                "authors": [
                    "V Uma Maheswari",
                    "R Aluvalu",
                    "KK Chennam"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:lmc2jWPfTJgC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Performance analysis of various encryption algorithms for usage in multistage encryption for securing data in cloud",
                "year": 2017,
                "authors": [
                    "KK Chennam",
                    "L Muddana",
                    "RK Aluvalu"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rHQkh6MAAAAJ&citation_for_view=rHQkh6MAAAAJ:35r97b3x0nAC",
                "abstract": null
            }
        ],
        "info": {
            "name": "Dr RajaniKanth Aluvalu",
            "affiliations": "Director, SIT,symbiosis International(Deemed University),Hyderabad,India",
            "email": "Verified email at ieee.org",
            "website": "https://rajnikanthteachingprofile.weebly.com/",
            "interests": [
                {
                    "title": "High Performance Computing",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:high_performance_computing",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Ahigh_performance_computing"
                },
                {
                    "title": "AI",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:ai",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Aai"
                },
                {
                    "title": "Data analytics",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:data_analytics",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Adata_analytics"
                },
                {
                    "title": "Teaching & Learning",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:teaching_%26_learning",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Ateaching_%2526_learning"
                }
            ],
            "thumbnail": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=rHQkh6MAAAAJ&citpid=7",
            "graph": [
                {
                    "year": 2015,
                    "citations": 8
                },
                {
                    "year": 2016,
                    "citations": 30
                },
                {
                    "year": 2017,
                    "citations": 29
                },
                {
                    "year": 2018,
                    "citations": 50
                },
                {
                    "year": 2019,
                    "citations": 69
                },
                {
                    "year": 2020,
                    "citations": 60
                },
                {
                    "year": 2021,
                    "citations": 160
                },
                {
                    "year": 2022,
                    "citations": 252
                },
                {
                    "year": 2023,
                    "citations": 456
                },
                {
                    "year": 2024,
                    "citations": 373
                }
            ],
            "citations": {
                "all": 1526,
                "since_2019": 1400
            },
            "h_index": {
                "all": 23,
                "since_2019": 21
            },
            "i10_index": {
                "all": 44,
                "since_2019": 43
            }
        }
    },
    "Sunayana Sitaram": {
        "data": [
            {
                "source": "arxiv",
                "title": "A Survey of Multilingual Models for Automatic Speech Recognition",
                "year": 2022,
                "authors": [
                    "Hemant Yadav",
                    "Sunayana Sitaram"
                ],
                "link": "http://arxiv.org/abs/2202.12576v1",
                "abstract": "Although Automatic Speech Recognition (ASR) systems have achieved human-likeperformance for a few languages, the majority of the world's languages do nothave usable systems due to the lack of large speech datasets to train thesemodels. Cross-lingual transfer is an attractive solution to this problem,because low-resource languages can potentially benefit from higher-resourcelanguages either through transfer learning, or being jointly trained in thesame multilingual model. The problem of cross-lingual transfer has been wellstudied in ASR, however, recent advances in Self Supervised Learning areopening up avenues for unlabeled speech data to be used in multilingual ASRmodels, which can pave the way for improved performance on low-resourcelanguages. In this paper, we survey the state of the art in multilingual ASRmodels that are built with cross-lingual transfer in mind. We present bestpractices for building multilingual models from research across diverselanguages and techniques, discuss open questions and provide recommendationsfor future work."
            },
            {
                "source": "arxiv",
                "title": "M5 -- A Diverse Benchmark to Assess the Performance of Large Multimodal\n  Models Across Multilingual and Multicultural Vision-Language Tasks",
                "year": 2024,
                "authors": [
                    "Florian Schneider",
                    "Sunayana Sitaram"
                ],
                "link": "http://arxiv.org/abs/2407.03791v2",
                "abstract": "Since the release of ChatGPT, the field of Natural Language Processing hasexperienced rapid advancements, particularly in Large Language Models (LLMs)and their multimodal counterparts, Large Multimodal Models (LMMs). Despitetheir impressive capabilities, LLMs often exhibit significant performancedisparities across different languages and cultural contexts, as demonstratedby various text-only benchmarks. However, current research lacks suchbenchmarks for multimodal visio-linguistic settings. This work fills this gapby introducing M5, the first comprehensive benchmark designed to evaluate LMMson diverse vision-language tasks within a multilingual and multiculturalcontext. M5 includes eight datasets covering five tasks and $41$ languages,with a focus on underrepresented languages and culturally diverse images.Furthermore, we introduce two novel datasets, M5-VGR and M5-VLOD, including anew Visio-Linguistic Outlier Detection task, in which all evaluated open-sourcemodels fail to significantly surpass the random baseline. Through extensiveevaluation and analyses, we highlight substantial task-agnostic performancedisparities between high- and low-resource languages. Moreover, we show thatlarger models do not necessarily outperform smaller ones in a multilingualsetting."
            },
            {
                "source": "arxiv",
                "title": "A New Dataset for Natural Language Inference from Code-mixed\n  Conversations",
                "year": 2020,
                "authors": [
                    "Simran Khanuja",
                    "Sandipan Dandapat",
                    "Sunayana Sitaram",
                    "Monojit Choudhury"
                ],
                "link": "http://arxiv.org/abs/2004.05051v2",
                "abstract": "Natural Language Inference (NLI) is the task of inferring the logicalrelationship, typically entailment or contradiction, between a premise andhypothesis. Code-mixing is the use of more than one language in the sameconversation or utterance, and is prevalent in multilingual communities allover the world. In this paper, we present the first dataset for code-mixed NLI,in which both the premises and hypotheses are in code-mixed Hindi-English. Weuse data from Hindi movies (Bollywood) as premises, and crowd-source hypothesesfrom Hindi-English bilinguals. We conduct a pilot annotation study and describethe final annotation protocol based on observations from the pilot. Currently,the data collected consists of 400 premises in the form of code-mixedconversation snippets and 2240 code-mixed hypotheses. We conduct an extensiveanalysis to infer the linguistic phenomena commonly observed in the datasetobtained. We evaluate the dataset using a standard mBERT-based pipeline for NLIand report results."
            },
            {
                "source": "arxiv",
                "title": "Beyond Static Models and Test Sets: Benchmarking the Potential of\n  Pre-trained Models Across Tasks and Languages",
                "year": 2022,
                "authors": [
                    "Kabir Ahuja",
                    "Sandipan Dandapat",
                    "Sunayana Sitaram",
                    "Monojit Choudhury"
                ],
                "link": "http://arxiv.org/abs/2205.06356v2",
                "abstract": "Although recent Massively Multilingual Language Models (MMLMs) like mBERT andXLMR support around 100 languages, most existing multilingual NLP benchmarksprovide evaluation data in only a handful of these languages with littlelinguistic diversity. We argue that this makes the existing practices inmultilingual evaluation unreliable and does not provide a full picture of theperformance of MMLMs across the linguistic landscape. We propose that therecent work done in Performance Prediction for NLP tasks can serve as apotential solution in fixing benchmarking in Multilingual NLP by utilizingfeatures related to data and language typology to estimate the performance ofan MMLM on different languages. We compare performance prediction withtranslating test data with a case study on four different multilingualdatasets, and observe that these methods can provide reliable estimates of theperformance that are often on-par with the translation based approaches,without the need for any additional translation as well as evaluation costs."
            },
            {
                "source": "arxiv",
                "title": "On the Calibration of Massively Multilingual Language Models",
                "year": 2022,
                "authors": [
                    "Kabir Ahuja",
                    "Sunayana Sitaram",
                    "Sandipan Dandapat",
                    "Monojit Choudhury"
                ],
                "link": "http://arxiv.org/abs/2210.12265v1",
                "abstract": "Massively Multilingual Language Models (MMLMs) have recently gainedpopularity due to their surprising effectiveness in cross-lingual transfer.While there has been much work in evaluating these models for their performanceon a variety of tasks and languages, little attention has been paid on how wellcalibrated these models are with respect to the confidence in theirpredictions. We first investigate the calibration of MMLMs in the zero-shotsetting and observe a clear case of miscalibration in low-resource languages orthose which are typologically diverse from English. Next, we empirically showthat calibration methods like temperature scaling and label smoothing doreasonably well towards improving calibration in the zero-shot scenario. Wealso find that few-shot examples in the language can further help reduce thecalibration errors, often substantially. Overall, our work contributes towardsbuilding more reliable multilingual models by highlighting the issue of theirmiscalibration, understanding what language and model specific factorsinfluence it, and pointing out the strategies to improve the same."
            },
            {
                "source": "arxiv",
                "title": "Fairness in Language Models Beyond English: Gaps and Challenges",
                "year": 2023,
                "authors": [
                    "Krithika Ramesh",
                    "Sunayana Sitaram",
                    "Monojit Choudhury"
                ],
                "link": "http://arxiv.org/abs/2302.12578v2",
                "abstract": "With language models becoming increasingly ubiquitous, it has becomeessential to address their inequitable treatment of diverse demographic groupsand factors. Most research on evaluating and mitigating fairness harms has beenconcentrated on English, while multilingual models and non-English languageshave received comparatively little attention. This paper presents a survey offairness in multilingual and non-English contexts, highlighting theshortcomings of current research and the difficulties faced by methods designedfor English. We contend that the multitude of diverse cultures and languagesacross the world makes it infeasible to achieve comprehensive coverage in termsof constructing fairness datasets. Thus, the measurement and mitigation ofbiases must evolve beyond the current dataset-driven practices that arenarrowly focused on specific dimensions and types of biases and, therefore,impossible to scale across languages and cultures."
            },
            {
                "source": "arxiv",
                "title": "Analysing the Masked predictive coding training criterion for\n  pre-training a Speech Representation Model",
                "year": 2023,
                "authors": [
                    "Hemant Yadav",
                    "Sunayana Sitaram",
                    "Rajiv Ratn Shah"
                ],
                "link": "http://arxiv.org/abs/2303.06982v3",
                "abstract": "Recent developments in pre-trained speech representation utilizingself-supervised learning (SSL) have yielded exceptional results on a variety ofdownstream tasks. One such technique, known as masked predictive coding (MPC),has been employed by some of the most high-performing models. In this study, weinvestigate the impact of MPC loss on the type of information learnt at variouslayers in the HuBERT model, using nine probing tasks. Our findings indicatethat the amount of content information learned at various layers of the HuBERTmodel has a positive correlation to the MPC loss. Additionally, it is alsoobserved that any speaker-related information learned at intermediate layers ofthe model, is an indirect consequence of the learning process, and thereforecannot be controlled using the MPC loss. These findings may serve asinspiration for further research in the speech community, specifically in thedevelopment of new pre-training tasks or the exploration of new pre-trainingcriterion's that directly preserves both speaker and content information atvarious layers of a learnt model."
            },
            {
                "source": "arxiv",
                "title": "On Evaluating and Mitigating Gender Biases in Multilingual Settings",
                "year": 2023,
                "authors": [
                    "Aniket Vashishtha",
                    "Kabir Ahuja",
                    "Sunayana Sitaram"
                ],
                "link": "http://arxiv.org/abs/2307.01503v1",
                "abstract": "While understanding and removing gender biases in language models has been along-standing problem in Natural Language Processing, prior research work hasprimarily been limited to English. In this work, we investigate some of thechallenges with evaluating and mitigating biases in multilingual settings whichstem from a lack of existing benchmarks and resources for bias evaluationbeyond English especially for non-western context. In this paper, we firstcreate a benchmark for evaluating gender biases in pre-trained masked languagemodels by extending DisCo to different Indian languages using humanannotations. We extend various debiasing methods to work beyond English andevaluate their effectiveness for SOTA massively multilingual models on ourproposed metric. Overall, our work highlights the challenges that arise whilestudying social biases in multilingual settings and provides resources as wellas mitigation techniques to take a step toward scaling to more languages."
            },
            {
                "source": "arxiv",
                "title": "A Unified Framework and Dataset for Assessing Societal Bias in\n  Vision-Language Models",
                "year": 2024,
                "authors": [
                    "Ashutosh Sathe",
                    "Prachi Jain",
                    "Sunayana Sitaram"
                ],
                "link": "http://arxiv.org/abs/2402.13636v2",
                "abstract": "Vision-language models (VLMs) have gained widespread adoption in bothindustry and academia. In this study, we propose a unified framework forsystematically evaluating gender, race, and age biases in VLMs with respect toprofessions. Our evaluation encompasses all supported inference modes of therecent VLMs, including image-to-text, text-to-text, text-to-image, andimage-to-image. Additionally, we propose an automated pipeline to generatehigh-quality synthetic datasets that intentionally conceal gender, race, andage information across different professional domains, both in generated textand images. The dataset includes action-based descriptions of each professionand serves as a benchmark for evaluating societal biases in vision-languagemodels (VLMs). In our comparative analysis of widely used VLMs, we haveidentified that varying input-output modalities lead to discernible differencesin bias magnitudes and directions. Additionally, we find that VLM modelsexhibit distinct biases across different bias attributes we investigated. Wehope our work will help guide future progress in improving VLMs to learnsocially unbiased representations. We will release our data and code."
            },
            {
                "source": "arxiv",
                "title": "MS-HuBERT: Mitigating Pre-training and Inference Mismatch in Masked\n  Language Modelling methods for learning Speech Representations",
                "year": 2024,
                "authors": [
                    "Hemant Yadav",
                    "Sunayana Sitaram",
                    "Rajiv Ratn Shah"
                ],
                "link": "http://arxiv.org/abs/2406.05661v2",
                "abstract": "In recent years, self-supervised pre-training methods have gained significanttraction in learning high-level information from raw speech. Among thesemethods, HuBERT has demonstrated SOTA performance in automatic speechrecognition (ASR). However, HuBERT's performance lags behind data2vec due todisparities in pre-training strategies. In this paper, we propose (i) a Swapmethod to address pre-training and inference mismatch observed in HuBERT and(ii) incorporates Multicluster masked prediction loss for more effectiveutilization of the models capacity. The resulting method is, MS-HuBERT, anend-to-end self-supervised pre-training method for learning robust speechrepresentations. It beats vanilla HuBERT on the ASR Librispeech benchmark onaverage by a 5% margin when evaluated on different finetuning splits.Additionally, we demonstrate that the learned embeddings obtained duringpre-training encode essential information for improving performance of contentbased tasks such as ASR."
            },
            {
                "source": "acmdl",
                "title": "Two methods for assessing oral reading prosody",
                "year": 2011,
                "authors": [
                    "Minh Duong",
                    "Jack Mostow",
                    "Sunayana Sitaram"
                ],
                "link": "https://dl.acm.org/doi/10.1145/1998384.1998388",
                "abstract": "We compare two types of models to assess the prosody of children's oral reading. Template models measure how well the child's prosodic contour in reading a given sentence correlates in pitch, intensity, pauses, or word reading times with an adult ..."
            },
            {
                "source": "acmdl",
                "title": "A Hindi speech recognizer for an agricultural video search application",
                "year": 2013,
                "authors": [
                    "Kalika Bali",
                    "Sunayana Sitaram",
                    "Sebastien Cuendet",
                    "Indrani Medhi"
                ],
                "link": "https://dl.acm.org/doi/10.1145/2442882.2442889",
                "abstract": "Voice user interfaces for ICTD applications have immense potential in their ability to reach to a large illiterate or semi-literate population in these regions where text-based interfaces are of little use. However, building speech systems for a new ..."
            },
            {
                "source": "dblp",
                "title": "MAPLE: Multilingual Evaluation of Parameter Efficient Finetuning of Large Language Models.",
                "year": 2024,
                "authors": [
                    "Divyanshu Aggarwal",
                    "Ashutosh Sathe",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2401.07598",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "MAFIA: Multi-Adapter Fused Inclusive LanguAge Models.",
                "year": 2024,
                "authors": [
                    "Prachi Jain",
                    "Ashutosh Sathe",
                    "Varun Gumma",
                    "Kabir Ahuja",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2402.07519",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "CultureLLM: Incorporating Cultural Differences into Large Language Models.",
                "year": 2024,
                "authors": [
                    "Cheng Li",
                    "Mengzhou Chen",
                    "Jindong Wang 0001",
                    "Sunayana Sitaram",
                    "Xing Xie 0001"
                ],
                "link": "https://doi.org/10.48550/arXiv.2402.10946",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "A Unified Framework and Dataset for Assessing Gender Bias in Vision-Language Models.",
                "year": 2024,
                "authors": [
                    "Ashutosh Sathe",
                    "Prachi Jain",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2402.13636",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Private Benchmarking to Prevent Contamination and Improve Comparative Evaluation of LLMs.",
                "year": 2024,
                "authors": [
                    "Nishanth Chandran",
                    "Sunayana Sitaram",
                    "Divya Gupta 0001",
                    "Rahul Sharma 0001",
                    "Kashish Mittal",
                    "Manohar Swaminathan 0001"
                ],
                "link": "https://doi.org/10.48550/arXiv.2403.00393",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "DOSA: A Dataset of Social Artifacts from Different Indian Geographical Subcultures.",
                "year": 2024,
                "authors": [
                    "Agrima Seth",
                    "Sanchit Ahuja",
                    "Kalika Bali",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2403.14651",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "METAL: Towards Multilingual Meta-Evaluation.",
                "year": 2024,
                "authors": [
                    "Rishav Hada",
                    "Varun Gumma",
                    "Mohamed Ahmed",
                    "Kalika Bali",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2404.01667",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Bridging the Gap: Dynamic Learning Strategies for Improving Multilingual Performance in LLMs.",
                "year": 2024,
                "authors": [
                    "Somnath Kumar",
                    "Vaibhav Balloli",
                    "Mercy Ranjit",
                    "Kabir Ahuja",
                    "Tanuja Ganu",
                    "Sunayana Sitaram",
                    "Kalika Bali",
                    "Akshay Nambi 0001"
                ],
                "link": "https://doi.org/10.48550/arXiv.2405.18359",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Beyond Metrics: Evaluating LLMs' Effectiveness in Culturally Nuanced, Low-Resource Real-World Scenarios.",
                "year": 2024,
                "authors": [
                    "Millicent Ochieng",
                    "Varun Gumma",
                    "Sunayana Sitaram",
                    "Jindong Wang 0001",
                    "Vishrav Chaudhary",
                    "Keshet Ronen",
                    "Kalika Bali",
                    "Jacki O'Neill"
                ],
                "link": "https://doi.org/10.48550/arXiv.2406.00343",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "MS-HuBERT: Mitigating Pre-training and Inference Mismatch in Masked Language Modelling methods for learning Speech Representations.",
                "year": 2024,
                "authors": [
                    "Hemant Yadav",
                    "Sunayana Sitaram",
                    "Rajiv Ratn Shah"
                ],
                "link": "https://doi.org/10.48550/arXiv.2406.05661",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Cultural Conditioning or Placebo? On the Effectiveness of Socio-Demographic Prompting.",
                "year": 2024,
                "authors": [
                    "Sagnik Mukherjee",
                    "Muhammad Farid Adilazuarda",
                    "Sunayana Sitaram",
                    "Kalika Bali",
                    "Alham Fikri Aji",
                    "Monojit Choudhury"
                ],
                "link": "https://doi.org/10.48550/arXiv.2406.11661",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "PARIKSHA : A Large-Scale Investigation of Human-LLM Evaluator Agreement on Multilingual and Multi-Cultural Data.",
                "year": 2024,
                "authors": [
                    "Ishaan Watts",
                    "Varun Gumma",
                    "Aditya Yadavalli",
                    "Vivek Seshadri",
                    "Manohar Swaminathan 0001",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2406.15053",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Teaching LLMs to Abstain across Languages via Multilingual Feedback.",
                "year": 2024,
                "authors": [
                    "Shangbin Feng",
                    "Weijia Shi",
                    "Yike Wang 0002",
                    "Wenxuan Ding 0001",
                    "Orevaoghene Ahia",
                    "Shuyue Stella Li",
                    "Vidhisha Balachandran",
                    "Sunayana Sitaram",
                    "Yulia Tsvetkov"
                ],
                "link": "https://doi.org/10.48550/arXiv.2406.15948",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Improving Self Consistency in LLMs through Probabilistic Tokenization.",
                "year": 2024,
                "authors": [
                    "Ashutosh Sathe",
                    "Divyanshu Aggarwal",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2407.03678",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "M5 - A Diverse Benchmark to Assess the Performance of Large Multimodal Models Across Multilingual and Multicultural Vision-Language Tasks.",
                "year": 2024,
                "authors": [
                    "Florian Schneider",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2407.03791",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "sPhinX: Sample Efficient Multilingual Instruction Fine-Tuning Through N-shot Guided Prompting.",
                "year": 2024,
                "authors": [
                    "Sanchit Ahuja",
                    "Kumar Tanmay",
                    "Hardik Hansrajbhai Chauhan",
                    "Barun Patra",
                    "Kriti Aggarwal",
                    "Luciano Del Corro",
                    "Arindam Mitra",
                    "Tejas Indulal Dhamecha",
                    "Ahmed Awadallah 0001",
                    "Monojit Choudhary",
                    "Vishrav Chaudhary",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2407.09879",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "A Survey of Code-switching: Linguistic and Social Perspectives for Language Technologies.",
                "year": 2023,
                "authors": [
                    "A. Seza Dogruz",
                    "Sunayana Sitaram",
                    "Barbara E. Bullock",
                    "Almeida Jacqueline Toribio"
                ],
                "link": "https://doi.org/10.48550/arXiv.2301.01967",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Fairness in Language Models Beyond English: Gaps and Challenges.",
                "year": 2023,
                "authors": [
                    "Krithika Ramesh",
                    "Sunayana Sitaram",
                    "Monojit Choudhury"
                ],
                "link": "https://doi.org/10.48550/arXiv.2302.12578",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "DiTTO: A Feature Representation Imitation Approach for Improving Cross-Lingual Transfer.",
                "year": 2023,
                "authors": [
                    "Shanu Kumar",
                    "Abbaraju Soujanya",
                    "Sandipan Dandapat",
                    "Sunayana Sitaram",
                    "Monojit Choudhury"
                ],
                "link": "https://doi.org/10.48550/arXiv.2303.02357",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Analysing the Masked predictive coding training criterion for pre-training a Speech Representation Model.",
                "year": 2023,
                "authors": [
                    "Hemant Yadav",
                    "Sunayana Sitaram",
                    "Rajiv Ratn Shah"
                ],
                "link": "https://doi.org/10.48550/arXiv.2303.06982",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "MEGA: Multilingual Evaluation of Generative AI.",
                "year": 2023,
                "authors": [
                    "Kabir Ahuja",
                    "Rishav Hada",
                    "Millicent Ochieng",
                    "Prachi Jain",
                    "Harshita Diddee",
                    "Samuel Maina",
                    "Tanuja Ganu",
                    "Sameer Segal",
                    "Maxamed Axmed",
                    "Kalika Bali",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2303.12528",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Breaking Language Barriers with a LEAP: Learning Strategies for Polyglot LLMs.",
                "year": 2023,
                "authors": [
                    "Akshay Uttama Nambi",
                    "Vaibhav Balloli",
                    "Mercy Prasanna Ranjit",
                    "Tanuja Ganu",
                    "Kabir Ahuja",
                    "Sunayana Sitaram",
                    "Kalika Bali"
                ],
                "link": "https://doi.org/10.48550/arXiv.2305.17740",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "On Evaluating and Mitigating Gender Biases in Multilingual Settings.",
                "year": 2023,
                "authors": [
                    "Aniket Vashishtha",
                    "Kabir Ahuja",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2307.01503",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?",
                "year": 2023,
                "authors": [
                    "Rishav Hada",
                    "Varun Gumma",
                    "Adrian de Wynter",
                    "Harshita Diddee",
                    "Mohamed Ahmed",
                    "Monojit Choudhury",
                    "Kalika Bali",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2309.07462",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Partial Rank Similarity Minimization Method for Quality MOS Prediction of Unseen Speech Synthesis Systems in Zero-Shot and Semi-supervised setting.",
                "year": 2023,
                "authors": [
                    "Hemant Yadav",
                    "Erica Cooper",
                    "Junichi Yamagishi",
                    "Sunayana Sitaram",
                    "Rajiv Ratn Shah"
                ],
                "link": "https://doi.org/10.48550/arXiv.2310.05078",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Representativeness as a Forgotten Lesson for Multilingual and Code-switched Data Collection and Preparation.",
                "year": 2023,
                "authors": [
                    "A. Seza Dogruz",
                    "Sunayana Sitaram",
                    "Zheng Xin Yong"
                ],
                "link": "https://doi.org/10.48550/arXiv.2310.20470",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "MEGAVERSE: Benchmarking Large Language Models Across Languages, Modalities, Models and Tasks.",
                "year": 2023,
                "authors": [
                    "Sanchit Ahuja",
                    "Divyanshu Aggarwal",
                    "Varun Gumma",
                    "Ishaan Watts",
                    "Ashutosh Sathe",
                    "Millicent Ochieng",
                    "Rishav Hada",
                    "Prachi Jain",
                    "Maxamed Axmed",
                    "Kalika Bali",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.48550/arXiv.2311.07463",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "A Survey of Multilingual Models for Automatic Speech Recognition.",
                "year": 2022,
                "authors": [
                    "Hemant Yadav",
                    "Sunayana Sitaram"
                ],
                "link": "https://arxiv.org/abs/2202.12576",
                "abstract": "Although Automatic Speech Recognition (ASR) systems have achieved human-like performance for a few languages, the majority of the world's languages do not have usable systems due to the lack of large speech datasets to train these models. Cross-lingual transfer is an attractive solution to this problem, because low-resource languages can potentially benefit from higher-resource languages either through transfer learning, or being jointly trained in the same multilingual model. The problem of cross-lingual transfer has been well studied in ASR, however, recent advances in Self Supervised Learning are opening up avenues for unlabeled speech data to be used in multilingual ASR models, which can pave the way for improved performance on low-resource languages. In this paper, we survey the state of the art in multilingual ASR models that are built with cross-lingual transfer in mind. We present best practices for building multilingual models from research across diverse languages and techniques, discuss open questions and provide recommendations for future work."
            },
            {
                "source": "dblp",
                "title": "Multilingual CheckList: Generation and Evaluation.",
                "year": 2022,
                "authors": [
                    "Karthikeyan K",
                    "Shaily Bhatt",
                    "Pankaj Singh",
                    "Somak Aditya",
                    "Sandipan Dandapat",
                    "Sunayana Sitaram",
                    "Monojit Choudhury"
                ],
                "link": "https://doi.org/10.48550/arXiv.2203.12865",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Beyond Static Models and Test Sets: Benchmarking the Potential of Pre-trained Models Across Tasks and Languages.",
                "year": 2022,
                "authors": [
                    "Kabir Ahuja",
                    "Sandipan Dandapat",
                    "Sunayana Sitaram",
                    "Monojit Choudhury"
                ],
                "link": "https://doi.org/10.48550/arXiv.2205.06356",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "On the Calibration of Massively Multilingual Language Models.",
                "year": 2022,
                "authors": [
                    "Kabir Ahuja",
                    "Sunayana Sitaram",
                    "Sandipan Dandapat",
                    "Monojit Choudhury"
                ],
                "link": "https://doi.org/10.48550/arXiv.2210.12265",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Benchmarking Evaluation Metrics for Code-Switching Automatic Speech Recognition.",
                "year": 2022,
                "authors": [
                    "Injy Hamed",
                    "Amir Hussein",
                    "Oumnia Chellah",
                    "Shammur Absar Chowdhury",
                    "Hamdy Mubarak",
                    "Sunayana Sitaram",
                    "Nizar Habash",
                    "Ahmed Ali 0002"
                ],
                "link": "https://doi.org/10.48550/arXiv.2211.16319",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Multilingual and code-switching ASR challenges for low resource Indian languages.",
                "year": 2021,
                "authors": [
                    "Anuj Diwan",
                    "Rakesh Vaideeswaran",
                    "Sanket Shah",
                    "Ankita Singh",
                    "Srinivasa Raghavan K. M.",
                    "Shreya Khare",
                    "Vinit Unni",
                    "Saurabh Vyas",
                    "Akash Rajpuria",
                    "Chiranjeevi Yarra",
                    "Ashish R. Mittal",
                    "Prasanta Kumar Ghosh",
                    "Preethi Jyothi",
                    "Kalika Bali",
                    "Vivek Seshadri",
                    "Sunayana Sitaram",
                    "Samarth Bharadwaj",
                    "Jai Nanavati",
                    "Raoul Nanavati",
                    "Karthik Sankaranarayanan",
                    "Tejaswi Seeram",
                    "Basil Abraham"
                ],
                "link": "https://arxiv.org/abs/2104.00235",
                "abstract": "Recently, there is increasing interest in multilingual automatic speech recognition (ASR) where a speech recognition system caters to multiple low resource languages by taking advantage of low amounts of labeled corpora in multiple languages. With multilingualism becoming common in today's world, there has been increasing interest in code-switching ASR as well. In code-switching, multiple languages are freely interchanged within a single sentence or between sentences. The success of low-resource multilingual and code-switching ASR often depends on the variety of languages in terms of their acoustics, linguistic characteristics as well as the amount of data available and how these are carefully considered in building the ASR system. In this challenge, we would like to focus on building multilingual and code-switching ASR systems through two different subtasks related to a total of seven Indian languages, namely Hindi, Marathi, Odia, Tamil, Telugu, Gujarati and Bengali. For this purpose, we provide a total of ~600 hours of transcribed speech data, comprising train and test sets, in these languages including two code-switched language pairs, Hindi-English and Bengali-English. We also provide a baseline recipe for both the tasks with a WER of 30.73% and 32.45% on the test sets of multilingual and code-switching subtasks, respectively."
            },
            {
                "source": "dblp",
                "title": "On the Universality of Deep COntextual Language Models.",
                "year": 2021,
                "authors": [
                    "Shaily Bhatt",
                    "Poonam Goyal",
                    "Sandipan Dandapat",
                    "Monojit Choudhury",
                    "Sunayana Sitaram"
                ],
                "link": "https://arxiv.org/abs/2109.07140",
                "abstract": "Deep Contextual Language Models (LMs) like ELMO, BERT, and their successors dominate the landscape of Natural Language Processing due to their ability to scale across multiple tasks rapidly by pre-training a single model, followed by task-specific fine-tuning. Furthermore, multilingual versions of such models like XLM-R and mBERT have given promising results in zero-shot cross-lingual transfer, potentially enabling NLP applications in many under-served and under-resourced languages. Due to this initial success, pre-trained models are being used as `Universal Language Models' as the starting point across diverse tasks, domains, and languages. This work explores the notion of `Universality' by identifying seven dimensions across which a universal model should be able to scale, that is, perform equally well or reasonably well, to be useful across diverse settings. We outline the current theoretical and empirical results that support model performance across these dimensions, along with extensions that may help address some of their current limitations. Through this survey, we lay the foundation for understanding the capabilities and limitations of massive contextual language models and help discern research gaps and directions for future work to make these LMs inclusive and fair to diverse applications, users, and linguistic phenomena."
            },
            {
                "source": "dblp",
                "title": "Predicting the Performance of Multilingual NLP Models.",
                "year": 2021,
                "authors": [
                    "Anirudh Srinivasan",
                    "Sunayana Sitaram",
                    "Tanuja Ganu",
                    "Sandipan Dandapat",
                    "Kalika Bali",
                    "Monojit Choudhury"
                ],
                "link": "https://arxiv.org/abs/2110.08875",
                "abstract": "Recent advancements in NLP have given us models like mBERT and XLMR that can serve over 100 languages. The languages that these models are evaluated on, however, are very few in number, and it is unlikely that evaluation datasets will cover all the languages that these models support. Potential solutions to the costly problem of dataset creation are to translate datasets to new languages or use template-filling based techniques for creation. This paper proposes an alternate solution for evaluating a model across languages which make use of the existing performance scores of the model on languages that a particular task has test sets for. We train a predictor on these performance scores and use this predictor to predict the model's performance in different evaluation settings. Our results show that our method is effective in filling the gaps in the evaluation for an existing set of languages, but might require additional improvements if we want it to generalize to unseen languages."
            },
            {
                "source": "dblp",
                "title": "A New Dataset for Natural Language Inference from Code-mixed Conversations.",
                "year": 2020,
                "authors": [
                    "Simran Khanuja",
                    "Sandipan Dandapat",
                    "Sunayana Sitaram",
                    "Monojit Choudhury"
                ],
                "link": "https://arxiv.org/abs/2004.05051",
                "abstract": "Natural Language Inference (NLI) is the task of inferring the logical relationship, typically entailment or contradiction, between a premise and hypothesis. Code-mixing is the use of more than one language in the same conversation or utterance, and is prevalent in multilingual communities all over the world. In this paper, we present the first dataset for code-mixed NLI, in which both the premises and hypotheses are in code-mixed Hindi-English. We use data from Hindi movies (Bollywood) as premises, and crowd-source hypotheses from Hindi-English bilinguals. We conduct a pilot annotation study and describe the final annotation protocol based on observations from the pilot. Currently, the data collected consists of 400 premises in the form of code-mixed conversation snippets and 2240 code-mixed hypotheses. We conduct an extensive analysis to infer the linguistic phenomena commonly observed in the dataset obtained. We evaluate the dataset using a standard mBERT-based pipeline for NLI and report results."
            },
            {
                "source": "dblp",
                "title": "GLUECoS : An Evaluation Benchmark for Code-Switched NLP.",
                "year": 2020,
                "authors": [
                    "Simran Khanuja",
                    "Sandipan Dandapat",
                    "Anirudh Srinivasan",
                    "Sunayana Sitaram",
                    "Monojit Choudhury"
                ],
                "link": "https://arxiv.org/abs/2004.12376",
                "abstract": "Code-switching is the use of more than one language in the same conversation or utterance. Recently, multilingual contextual embedding models, trained on multiple monolingual corpora, have shown promising results on cross-lingual and multilingual tasks. We present an evaluation benchmark, GLUECoS, for code-switched languages, that spans several NLP tasks in English-Hindi and English-Spanish. Specifically, our evaluation benchmark includes Language Identification from text, POS tagging, Named Entity Recognition, Sentiment Analysis, Question Answering and a new task for code-switching, Natural Language Inference. We present results on all these tasks using cross-lingual word embedding models and multilingual models. In addition, we fine-tune multilingual models on artificially generated code-switched data. Although multilingual models perform significantly better than cross-lingual models, our results show that in most tasks, across both language pairs, multilingual models fine-tuned on code-switched data perform best, showing that multilingual models can be further optimized for code-switching tasks."
            },
            {
                "source": "dblp",
                "title": "Learning to Recognize Code-switched Speech Without Forgetting Monolingual Speech Recognition.",
                "year": 2020,
                "authors": [
                    "Sanket Shah",
                    "Basil Abraham",
                    "Gurunath Reddy M",
                    "Sunayana Sitaram",
                    "Vikas Joshi"
                ],
                "link": "https://arxiv.org/abs/2006.00782",
                "abstract": "Recently, there has been significant progress made in Automatic Speech Recognition (ASR) of code-switched speech, leading to gains in accuracy on code-switched datasets in many language pairs. Code-switched speech co-occurs with monolingual speech in one or both languages being mixed. In this work, we show that fine-tuning ASR models on code-switched speech harms performance on monolingual speech. We point out the need to optimize models for code-switching while also ensuring that monolingual performance is not sacrificed. Monolingual models may be trained on thousands of hours of speech which may not be available for re-training a new model. We propose using the Learning Without Forgetting (LWF) framework for code-switched ASR when we only have access to a monolingual model and do not have the data it was trained on. We show that it is possible to train models using this framework that perform well on both code-switched and monolingual test sets. In cases where we have access to monolingual training data as well, we propose regularization strategies for fine-tuning models for code-switching without sacrificing monolingual accuracy. We report improvements in Word Error Rate (WER) in monolingual and code-switched test sets compared to baselines that use pooled data and simple fine-tuning."
            },
            {
                "source": "dblp",
                "title": "Learning not to Discriminate: Task Agnostic Learning for Improving Monolingual and Code-switched Speech Recognition.",
                "year": 2020,
                "authors": [
                    "Gurunath Reddy Madhumani",
                    "Sanket Shah",
                    "Basil Abraham",
                    "Vikas Joshi",
                    "Sunayana Sitaram"
                ],
                "link": "https://arxiv.org/abs/2006.05257",
                "abstract": "Recognizing code-switched speech is challenging for Automatic Speech Recognition (ASR) for a variety of reasons, including the lack of code-switched training data. Recently, we showed that monolingual ASR systems fine-tuned on code-switched data deteriorate in performance on monolingual speech recognition, which is not desirable as ASR systems deployed in multilingual scenarios should recognize both monolingual and code-switched speech with high accuracy. Our experiments indicated that this loss in performance could be mitigated by using certain strategies for fine-tuning and regularization, leading to improvements in both monolingual and code-switched ASR. In this work, we present further improvements over our previous work by using domain adversarial learning to train task agnostic models. We evaluate the classification accuracy of an adversarial discriminator and show that it can learn shared layer parameters that are task agnostic. We train end-to-end ASR systems starting with a pooled model that uses monolingual and code-switched data along with the adversarial discriminator. Our proposed technique leads to reductions in Word Error Rates (WER) in monolingual and code-switched test sets across three language pairs."
            },
            {
                "source": "dblp",
                "title": "Cross-lingual and Multilingual Spoken Term Detection for Low-Resource Indian Languages.",
                "year": 2020,
                "authors": [
                    "Sanket Shah",
                    "Satarupa Guha",
                    "Simran Khanuja",
                    "Sunayana Sitaram"
                ],
                "link": "https://arxiv.org/abs/2011.06226",
                "abstract": "Spoken Term Detection (STD) is the task of searching for words or phrases within audio, given either text or spoken input as a query. In this work, we use state-of-the-art Hindi, Tamil and Telugu ASR systems cross-lingually for lexical Spoken Term Detection in ten low-resource Indian languages. Since no publicly available dataset exists for Spoken Term Detection in these languages, we create a new dataset using a publicly available TTS dataset. We report a standard metric for STD, Mean Term Weighted Value (MTWV) and show that ASR systems built in languages that are phonetically similar to the target languages have higher accuracy, however, it is also possible to get high MTWV scores for dissimilar languages by using a relaxed phone matching algorithm. We propose a technique to bootstrap the Grapheme-to-Phoneme (g2p) mapping between all the languages under consideration using publicly available resources. Gains are obtained when we combine the output of multiple ASR systems and when we use language-specific Language Models. We show that it is possible to perform STD cross-lingually in a zero-shot manner without the need for any language-specific speech data. We plan to make the STD dataset available for other researchers interested in cross-lingual STD."
            },
            {
                "source": "dblp",
                "title": "A Survey of Code-switched Speech and Language Processing.",
                "year": 2019,
                "authors": [
                    "Sunayana Sitaram",
                    "Khyathi Raghavi Chandu",
                    "Sai Krishna Rallabandi",
                    "Alan W. Black"
                ],
                "link": "http://arxiv.org/abs/1904.00784",
                "abstract": "Code-switching, the alternation of languages within a conversation or utterance, is a common communicative phenomenon that occurs in multilingual communities across the world. This survey reviews computational approaches for code-switched Speech and Natural Language Processing. We motivate why processing code-switched text and speech is essential for building intelligent agents and systems that interact with users in multilingual communities. As code-switching data and resources are scarce, we list what is available in various code-switched language pairs with the language processing tasks they can be used for. We review code-switching research in various Speech and NLP applications, including language processing tools and end-to-end systems. We conclude with future directions and open problems in the field."
            },
            {
                "source": "dblp",
                "title": "End-to-End ASR for Code-switched Hindi-English Speech.",
                "year": 2019,
                "authors": [
                    "Brij Mohan Lal Srivastava",
                    "Basil Abraham",
                    "Sunayana Sitaram",
                    "Rupesh K. Mehta",
                    "Preethi Jyothi"
                ],
                "link": "http://arxiv.org/abs/1906.09426",
                "abstract": "End-to-end (E2E) models have been explored for large speech corpora and have been found to match or outperform traditional pipeline-based systems in some languages. However, most prior work on end-to-end models use speech corpora exceeding hundreds or thousands of hours. In this study, we explore end-to-end models for code-switched Hindi-English language with less than 50 hours of data. We utilize two specific measures to improve network performance in the low-resource setting, namely multi-task learning (MTL) and balancing the corpus to deal with the inherent class imbalance problem i.e. the skewed frequency distribution over graphemes. We compare the results of the proposed approaches with traditional, cascaded ASR systems. While the lack of data adversely affects the performance of end-to-end models, we see promising improvements with MTL and balancing the corpus."
            },
            {
                "source": "dblp",
                "title": "Unsung Challenges of Building and Deploying Language Technologies for Low Resource Language Communities.",
                "year": 2019,
                "authors": [
                    "Pratik Joshi",
                    "Christain Barnes",
                    "Sebastin Santy",
                    "Simran Khanuja",
                    "Sanket Shah",
                    "Anirudh Srinivasan",
                    "Satwik Bhattamishra",
                    "Sunayana Sitaram",
                    "Monojit Choudhury",
                    "Kalika Bali"
                ],
                "link": "http://arxiv.org/abs/1912.03457",
                "abstract": "In this paper, we examine and analyze the challenges associated with developing and introducing language technologies to low-resource language communities. While doing so, we bring to light the successes and failures of past work in this area, challenges being faced in doing so, and what they have achieved. Throughout this paper, we take a problem-facing approach and describe essential factors which the success of such technologies hinges upon. We present the various aspects in a manner which clarify and lay out the different tasks involved, which can aid organizations looking to make an impact in this area. We take the example of Gondi, an extremely-low resource Indian language, to reinforce and complement our discussion."
            },
            {
                "source": "dblp",
                "title": "Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation Learning.",
                "year": 2016,
                "authors": [
                    "Yulia Tsvetkov",
                    "Sunayana Sitaram",
                    "Manaal Faruqui",
                    "Guillaume Lample",
                    "Patrick Littell",
                    "David R. Mortensen",
                    "Alan W. Black",
                    "Lori S. Levin",
                    "Chris Dyer"
                ],
                "link": "http://arxiv.org/abs/1605.03832",
                "abstract": "We introduce polyglot language models, recurrent neural network models trained to predict symbol sequences in many different languages using shared representations of symbols and conditioning on typological information about the language to be predicted. We apply these to the problem of modeling phone sequences---a domain in which universal symbol inventories and cross-linguistically shared feature representations are a natural fit. Intrinsic evaluation on held-out perplexity, qualitative analysis of the learned representations, and extrinsic evaluation in two downstream applications that make use of phonetic features show (i) that polyglot models better generalize to held-out data than comparable monolingual models and (ii) that polyglot phonetic feature representations are of higher quality than those learned monolingually."
            },
            {
                "source": "dblp",
                "title": "Two methods for assessing oral reading prosody.",
                "year": 2011,
                "authors": [
                    "Minh Duong",
                    "Jack Mostow",
                    "Sunayana Sitaram"
                ],
                "link": "https://doi.org/10.1145/1998384.1998388",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Language modeling for code-mixing: The role of linguistic theory based synthetic data",
                "year": 2018,
                "authors": [
                    "A Pratapa",
                    "G Bhat",
                    "M Choudhury",
                    "S Sitaram",
                    "S Dandapat",
                    "K Bali"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:ULOm3_A8WrAC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Mega: Multilingual evaluation of generative ai",
                "year": 2023,
                "authors": [
                    "K Ahuja",
                    "H Diddee",
                    "R Hada",
                    "M Ochieng",
                    "K Ramesh",
                    "P Jain",
                    "A Nambi",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:70eg2SAEIzsC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "A survey of code-switched speech and language processing",
                "year": 2019,
                "authors": [
                    "S Sitaram",
                    "KR Chandu",
                    "SK Rallabandi",
                    "AW Black"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:Wp0gIr-vW9MC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "GLUECoS: An evaluation benchmark for code-switched NLP",
                "year": 2020,
                "authors": [
                    "S Khanuja",
                    "S Dandapat",
                    "A Srinivasan",
                    "S Sitaram",
                    "M Choudhury"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:qUcmZB5y_30C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Multilingual and code-switching ASR challenges for low resource Indian languages",
                "year": 2021,
                "authors": [
                    "A Diwan",
                    "R Vaideeswaran",
                    "S Shah",
                    "A Singh",
                    "S Raghavan",
                    "S Khare",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:j3f4tGmQtD8C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Interspeech 2018 Low Resource Automatic Speech Recognition Challenge for Indian Languages",
                "year": 2018,
                "authors": [
                    "BML Srivastava",
                    "S Sitaram",
                    "RK Mehta",
                    "KD Mohan",
                    "P Matani",
                    "S Satpal",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:qxL8FJ1GzNcC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Word embeddings for code-mixed language processing",
                "year": 2018,
                "authors": [
                    "A Pratapa",
                    "M Choudhury",
                    "S Sitaram"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:aqlVkmm33-oC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Polyglot neural language models: A case study in cross-lingual phonetic representation learning",
                "year": 2016,
                "authors": [
                    "Y Tsvetkov",
                    "S Sitaram",
                    "M Faruqui",
                    "G Lample",
                    "P Littell",
                    "D Mortensen",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:5nxA0vEk-isC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "A survey of code-switching: Linguistic and social perspectives for language technologies",
                "year": 2023,
                "authors": [
                    "AS Doruz",
                    "S Sitaram",
                    "BE Bullock",
                    "AJ Toribio"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:TFP_iSt0sucC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Speech synthesis of code-mixed text",
                "year": 2016,
                "authors": [
                    "S Sitaram",
                    "AW Black"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:3fE2CSJIrl8C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Crowdsourcing speech data for low-resource languages from low-income workers",
                "year": 2020,
                "authors": [
                    "B Abraham",
                    "D Goel",
                    "D Siddarth",
                    "K Bali",
                    "M Chopra",
                    "M Choudhury",
                    "P Joshi",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:-f6ydRqryjwC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Unsung challenges of building and deploying language technologies for low resource language communities",
                "year": 2019,
                "authors": [
                    "P Joshi",
                    "C Barnes",
                    "S Santy",
                    "S Khanuja",
                    "S Shah",
                    "A Srinivasan",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:7PzlFSSx8tAC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Curriculum design for code-switching: Experiments with language identification and language modeling with deep neural networks",
                "year": 2017,
                "authors": [
                    "M Choudhury",
                    "K Bali",
                    "S Sitaram",
                    "A Baheti"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:M3ejUd6NZC8C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Experiments with Cross-lingual Systems for Synthesis of Code-Mixed Text.",
                "year": 2016,
                "authors": [
                    "S Sitaram",
                    "SK Rallabandi",
                    "S Rijhwani",
                    "AW Black"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:8k81kl-MbHgC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "GCM: A toolkit for generating synthetic code-mixed text",
                "year": 2021,
                "authors": [
                    "MSZ Rizvi",
                    "A Srinivasan",
                    "T Ganu",
                    "M Choudhury",
                    "S Sitaram"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:iH-uZ7U-co4C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "A hindi speech recognizer for an agricultural video search application",
                "year": 2013,
                "authors": [
                    "K Bali",
                    "S Sitaram",
                    "S Cuendet",
                    "I Medhi"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:WF5omc3nYNoC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "A new dataset for natural language inference from code-mixed conversations",
                "year": 2020,
                "authors": [
                    "S Khanuja",
                    "S Dandapat",
                    "S Sitaram",
                    "M Choudhury"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:IWHjjKOFINEC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Phone merging for code-switched speech recognition",
                "year": 2018,
                "authors": [
                    "S Sivasankaran",
                    "BML Srivastava",
                    "S Sitaram",
                    "K Bali",
                    "M Choudhury"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:Zph67rFs4hoC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "A survey of multilingual models for automatic speech recognition",
                "year": 2022,
                "authors": [
                    "H Yadav",
                    "S Sitaram"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:NMxIlDl6LWMC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Two methods for assessing oral reading prosody",
                "year": 2011,
                "authors": [
                    "M Duong",
                    "J Mostow",
                    "S Sitaram"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PUxwYrkAAAAJ&citation_for_view=PUxwYrkAAAAJ:eQOLeE2rZwMC",
                "abstract": null
            }
        ],
        "info": {
            "name": "Sunayana Sitaram",
            "affiliations": "Microsoft Research India",
            "email": "Verified email at microsoft.com",
            "website": "https://www.microsoft.com/en-us/research/people/susitara/",
            "interests": [
                {
                    "title": "Multilingual NLP",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:multilingual_nlp",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Amultilingual_nlp"
                },
                {
                    "title": "evaluation",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:evaluation",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Aevaluation"
                },
                {
                    "title": "LLMs and culture",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:llms_and_culture",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Allms_and_culture"
                },
                {
                    "title": "multilingualism",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:multilingualism",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Amultilingualism"
                },
                {
                    "title": "LLMs",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:llms",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Allms"
                }
            ],
            "thumbnail": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=PUxwYrkAAAAJ&citpid=3",
            "graph": [
                {
                    "year": 2013,
                    "citations": 16
                },
                {
                    "year": 2014,
                    "citations": 14
                },
                {
                    "year": 2015,
                    "citations": 16
                },
                {
                    "year": 2016,
                    "citations": 28
                },
                {
                    "year": 2017,
                    "citations": 30
                },
                {
                    "year": 2018,
                    "citations": 70
                },
                {
                    "year": 2019,
                    "citations": 107
                },
                {
                    "year": 2020,
                    "citations": 173
                },
                {
                    "year": 2021,
                    "citations": 221
                },
                {
                    "year": 2022,
                    "citations": 319
                },
                {
                    "year": 2023,
                    "citations": 375
                },
                {
                    "year": 2024,
                    "citations": 479
                }
            ],
            "citations": {
                "all": 1859,
                "since_2019": 1677
            },
            "h_index": {
                "all": 23,
                "since_2019": 21
            },
            "i10_index": {
                "all": 42,
                "since_2019": 37
            }
        }
    },
    "Terence Tao": {
        "data": [
            {
                "source": "arxiv",
                "title": "A converse extrapolation theorem for translation invariant operators",
                "year": 1999,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/math/9912001v1",
                "abstract": "We prove the converse of Yano's extrapolation theorem for translationinvariant operators."
            },
            {
                "source": "arxiv",
                "title": "Some recent progress on the Restriction conjecture",
                "year": 2003,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/math/0303136v1",
                "abstract": "We survey recent developments on the Restriction conjecture."
            },
            {
                "source": "arxiv",
                "title": "Perelman's proof of the Poincar conjecture: a nonlinear PDE\n  perspective",
                "year": 2006,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/math/0610903v1",
                "abstract": "We discuss some of the key ideas of Perelman's proof of Poincar\\'e'sconjecture via the Hamilton program of using the Ricci flow, from theperspective of the modern theory of nonlinear partial differential equations."
            },
            {
                "source": "arxiv",
                "title": "What is good mathematics?",
                "year": 2007,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/math/0702396v1",
                "abstract": "Some personal thoughts and opinions on what ``good quality mathematics'' is,and whether one should try to define this term rigorously. As a case study, thestory of Szemer\\'edi's theorem is presented."
            },
            {
                "source": "arxiv",
                "title": "Ill-posedness for one-dimensional wave maps at the critical regularity",
                "year": 1998,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/math/9811169v2",
                "abstract": "We show that the wave map equation in $\\R^{1+1}$ is in general ill-posed inthe critical space $\\dot H^{1/2}$, and the Besov space $\\dot B^{1/2,1}_2$. Theproblem is attributed to the bad behaviour of the one-dimensional bilinearexpression $D^{-1}(f Dg)$ in these spaces."
            },
            {
                "source": "arxiv",
                "title": "The weak-type (1,1) of L \\log L homogeneous convolution operators",
                "year": 1999,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/math/9903165v2",
                "abstract": "We show that a homogeneous convolution kernel on an arbitrary homogeneousgroup which is L \\log L on the unit annulus is bounded on L^p for 1 < p <\\infty and is of weak-type (1,1), generalizing the result of Seeger. The proofis in a similar spirit to that of Christ and Rubio de Francia."
            },
            {
                "source": "arxiv",
                "title": "Arithmetic progressions and the primes - El Escorial lectures",
                "year": 2004,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/math/0411246v1",
                "abstract": "We describe some of the machinery behind recent progress in establishinginfinitely many arithmetic progressions of length $k$ in various sets ofintegers, in particular in arbitrary dense subsets of the integers, and in theprimes."
            },
            {
                "source": "arxiv",
                "title": "Global regularity for a logarithmically supercritical defocusing\n  nonlinear wave equation for spherically symmetric data",
                "year": 2006,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/math/0606145v1",
                "abstract": "We establish global regularity for the logarithmically energy-supercriticalwave equation $\\Box u = u^5 \\log(2+u^2)$ in three spatial dimensions forspherically symmetric initial data, by modifying an argument of Ginibre, Sofferand Velo \\cite{gsv} for the energy-critical equation. This example demonstratesthat critical regularity arguments can penetrate very slightly into thesupercritical regime."
            },
            {
                "source": "arxiv",
                "title": "Spherically averaged endpoint Strichartz estimates for the\n  two-dimensional Schrdinger equation",
                "year": 1998,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/math/9811168v2",
                "abstract": "The endpoint Strichartz estimates for the Schr\\\"odinger equation are known tobe false in two dimensions. However, if one averages the solution in $L^2$ inthe angular variable, we show that the homogeneous endpoint and the retardedhalf-endpoint estimates hold, but the full retarded endpoint fails. Inparticular, the original versions of these estimates hold for radial data."
            },
            {
                "source": "arxiv",
                "title": "Endpoint bilinear restriction theorems for the cone, and some sharp null\n  form estimates",
                "year": 1999,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/math/9909066v2",
                "abstract": "Recently Wolff obtained a nearly sharp $L^2$ bilinear restriction theorem forbounded subsets of the cone in general dimension. We obtain the endpoint ofWolff's estimate and generalize to the case when one of the subsets is large.As a consequence, we are able to deduce some nearly-sharp $L^p$ null formestimates."
            },
            {
                "source": "pubmed",
                "title": "Undecidable Translational Tilings with Only Two Tiles, or One Nonabelian Tile.",
                "year": 2023,
                "authors": [
                    "Greenfeld R",
                    "Tao T."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/38022896",
                "abstract": "We construct an example of a group G=Z2G0 for a finite abelian group G0, a subset E of G0, and two finite subsets F1,F2 of G, such that it is undecidable in ZFC whether Z2E can be tiled by translations of F1,F2. In particular, this implies that this tiling problem is aperiodic, in the sense that (in the standard universe of ZFC) there exist translational tilings of E by the tiles F1,F2, but no periodic tilings. Previously, such aperiodic or undecidable translational tilings were only constructed for sets of eleven or more tiles (mostly in Z2). A similar construction also applies for G=Zd for sufficiently large d. If one allows the group G0 to be non-abelian, a variant of the construction produces an undecidable translational tiling with only one tile F. The argument proceeds by first observing that a single tiling equation is able to encode an arbitrary system of tiling equations, which in turn can encode an arbitrary system of certain functional equations once one has two or more tiles. In particular, one can use two tiles to encode tiling problems for an arbitrary number of tiles.              Keywords:                    Aperiodic tiling; Decidability; Translational tiling."
            },
            {
                "source": "pubmed",
                "title": "Structural basis of protein phosphatase 1 regulation.",
                "year": 2004,
                "authors": [
                    "Terrak M",
                    "Kerff F",
                    "Langsetmo K",
                    "Tao T",
                    "Dominguez R."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/15164081",
                "abstract": "The coordinated and reciprocal action of serine/threonine (Ser/Thr) protein kinases and phosphatases produces transient phosphorylation, a fundamental regulatory mechanism for many biological processes. The human genome encodes a far greater number of Ser/Thr protein kinases than of phosphatases. Protein phosphatase 1 (PP1), in particular, is ubiquitously distributed and regulates a broad range of cellular functions, including glycogen metabolism, cell-cycle progression and muscle relaxation. PP1 has evolved effective catalytic machinery but lacks substrate specificity. Substrate specificity is conferred upon PP1 through interactions with a large number of regulatory subunits. The regulatory subunits are generally unrelated, but most possess the RVxF motif, a canonical PP1-binding sequence. Here we reveal the crystal structure at 2.7 A resolution of the complex between PP1 and a 34-kDa N-terminal domain of the myosin phosphatase targeting subunit MYPT1. MYPT1 is the protein that regulates PP1 function in smooth muscle relaxation. Structural elements amino- and carboxy-terminal to the RVxF motif of MYPT1 are positioned in a way that leads to a pronounced reshaping of the catalytic cleft of PP1, contributing to the increased myosin specificity of this complex. The structure has general implications for the control of PP1 activity by other regulatory subunits."
            },
            {
                "source": "pubmed",
                "title": "Perfectly Packing a Square by Squares of Nearly Harmonic Sidelength.",
                "year": 2024,
                "authors": [
                    "Tao T."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/38720937",
                "abstract": "A well-known open problem of Meir and Moser asks if the squares of sidelength 1/n for n2 can be packed perfectly into a rectangle of area n=2n-2=2/6-1. In this paper we show that for any 1/2<t<1, and any n0 that is sufficiently large depending on t, the squares of sidelength n-t for nn0 can be packed perfectly into a square of area n=n0n-2t. This was previously known (if one packs a rectangle instead of a square) for 1/2<t2/3 (in which case one can take n0=1).              Keywords:                    Harmonic series; MeirMoser problem; Square packing."
            },
            {
                "source": "pubmed",
                "title": "Cross-linking between the regulatory regions of troponin-I and troponin-C abolishes the inhibitory function of troponin.",
                "year": 2002,
                "authors": [
                    "Luo Y",
                    "Li B",
                    "Yang G",
                    "Gergely J",
                    "Tao T."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/12379133",
                "abstract": "We reported previously that both residues 48 and 82 on opposite sides of troponin-C's (TnC's) N-terminal regulatory hydrophobic cleft photo-cross-linked to Met121 of troponin-I (TnI) [Luo, Y., Leszyk, J., Qian, Y., Gergely, J., and Tao, T. (1999) Biochemistry 38, 6678-6688]. Here we report that the Ca2+-absent inhibitory activity of troponin (Tn) was progressively lost as the extent of photo-cross-linking increased. To extend these studies, we constructed a mutant TnI with a single cysteine at residue 121 (TnI121). In Tn complexes containing TnI121 and mutant TnCs with a single cysteine at positions 12, 48, 82, 98, or 125 (TnC12, TnC48 etc.), TnI121 formed disulfide cross-links primarily with TnC48 and TnC82 when Ca2+ was present, and with only TnC48 when Ca2+ was absent. These results indicate that TnI Met121 is situated within the N-domain hydrophobic cleft of TnC in the presence of Ca2+, and that it moves out of the cleft upon Ca2+ removal but remains within the vicinity of TnC. Activity assays revealed that the Met121 to Cys mutation in TnI121 reduced the Ca2+-present activation of Tn, indicating that Met121 is important in hydrophobic interactions between this TnI region and TnC's N-domain cleft. The formation of a disulfide cross-link between TnI121 and TnC48 or TnC82 abolished the Ca2+-absent inhibitory activity of Tn, indicating that the movement of the Met121 region of TnI out of TnC's N-domain cleft is essential for the occurrence of further events in the inhibitory process of skeletal muscle contraction. On the basis of these and other results, a simple mechanism for Ca2+ regulation of skeletal muscle contraction is presented and discussed."
            },
            {
                "source": "pubmed",
                "title": "Troponin-I interacts with the Met47 region of skeletal muscle actin. Implications for the mechanism of thin filament regulation by calcium.",
                "year": 2002,
                "authors": [
                    "Luo Y",
                    "Leszyk J",
                    "Li B",
                    "Li Z",
                    "Gergely J",
                    "Tao T."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/11866508",
                "abstract": "Striated muscles are regulated by Ca(2+) via the thin filament proteins troponin (Tn) and tropomyosin (Tm). In the absence of Ca(2+), contraction is inhibited, whereas myosin-actin interaction and contraction can take place in its presence. Although it is well established that the interaction of troponin-I (TnI), the inhibitory subunit of Tn, with actin is required for the inhibition process and that there are two separate actin-binding regions in TnI that interact with actin, the molecular mechanism of this inhibition process is still not clear. Using TnI mutants with photocrosslinking probes attached to genetically engineered cysteine residues in each of the two actin-binding regions, we show that both regions are close to Met47 of actin in its outer domain. It has been proposed that the Ca(2+)-induced activation of contraction involves the movement of Tm from the outer to the inner domain of the actin filament. On the basis of our results presented here, we propose that the position of Tm at the outer domain of actin in the Ca(2+)-free state is stabilized by the presence of TnI over actin's outer domain via mutual interactions of all three components. In the presence of Ca(2+), TnI's actin-binding regions dissociate from actin allowing Tm to move toward actin's inner domain."
            },
            {
                "source": "acmdl",
                "title": "The condition number of a randomly perturbed matrix",
                "year": 2007,
                "authors": [
                    "Van H. Vu",
                    "Terence Tao"
                ],
                "link": "https://dl.acm.org/doi/10.1145/1250790.1250828",
                "abstract": "Let M be an arbitrary n by n matrix. We study the conditionnumber a random perturbation M+Nn of M, where Nn is arandom matrix. It is shown that, under very general conditions on M and Mn, the condition number of M+Nn is polynomial in nwith very high ..."
            },
            {
                "source": "acmdl",
                "title": "On random pm 1 matrices",
                "year": 2005,
                "authors": [
                    "Terence Tao",
                    "Van Vu"
                ],
                "link": "https://dl.acm.org/doi/10.1145/1060590.1060655",
                "abstract": "We proved several results concerning the determinant of a random pm 1 matrix. In particular, we show that with high probability, the determinant has absolute value very close to n!."
            },
            {
                "source": "nature",
                "title": "Inhibition of mutant troponin C activity by an intra-domain disulphide bond",
                "year": 1990,
                "authors": [
                    "Zenon Grabarek1",
                    "Ruo-Ying Tan1",
                    "Jing Wang1",
                    "Terence Tao12",
                    "John Gergely123"
                ],
                "link": "https://www.nature.com/articles/345132a0",
                "abstract": "Triggering of contraction in striated muscles involves a conformational transition in the N-terminal domain of troponin C, the calcium-binding component of thin filaments. We have designed a mutant troponin C in which the key conformational transition and the calcium-regulatory activity are reversibly blocked by the formation of a disulphide bridge. Our results may be applicable to other proteins of the same family of calcium-binding proteins."
            },
            {
                "source": "nature",
                "title": "Searching for singularities in the NavierStokes equations",
                "year": 2019,
                "authors": [
                    "Terence Tao1"
                ],
                "link": "https://www.nature.com/articles/s42254-019-0068-9",
                "abstract": null
            },
            null,
            null,
            {
                "source": "nature",
                "title": "Structural basis of protein phosphatase 1 regulation",
                "year": 2004,
                "authors": [
                    "Mohammed Terrak",
                    "Frederic Kerff",
                    "Knut Langsetmo1",
                    "Terence Tao1",
                    "Roberto Dominguez1"
                ],
                "link": "https://www.nature.com/articles/nature02582",
                "abstract": "The coordinated and reciprocal action of serine/threonine (Ser/Thr) protein kinases and phosphatases produces transient phosphorylation, a fundamental regulatory mechanism for many biological processes. The human genome encodes a far greater number of Ser/Thr protein kinases than of phosphatases. Protein phosphatase 1 (PP1), in particular, is ubiquitously distributed and regulates a broad range of cellular functions, including glycogen metabolism, cell-cycle progression and muscle relaxation1,2. PP1 has evolved effective catalytic machinery but lacks substrate specificity. Substrate specificity is conferred upon PP1 through interactions with a large number of regulatory subunits. The regulatory subunits are generally unrelated, but most possess the RVxF motif, a canonical PP1-binding sequence. Here we reveal the crystal structure at 2.7 resolution of the complex between PP1 and a 34-kDa N-terminal domain of the myosin phosphatase targeting subunit MYPT1. MYPT1 is the protein that regulates PP1 function in smooth muscle relaxation3. Structural elements amino- and carboxy-terminal to the RVxF motif of MYPT1 are positioned in a way that leads to a pronounced reshaping of the catalytic cleft of PP1, contributing to the increased myosin specificity of this complex. The structure has general implications for the control of PP1 activity by other regulatory subunits."
            },
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            null,
            {
                "source": "dblp",
                "title": "Perfectly Packing a Square by Squares of Nearly Harmonic Sidelength.",
                "year": 2024,
                "authors": [
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1007/s00454-023-00523-y",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Undecidable Translational Tilings with Only Two Tiles, or One Nonabelian Tile.",
                "year": 2023,
                "authors": [
                    "Rachel Greenfeld",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1007/s00454-022-00426-4",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Some remarks on the lonely runner conjecture.",
                "year": 2018,
                "authors": [
                    "Terence Tao"
                ],
                "link": "https://cdm.ucalgary.ca/cdm/index.php/cdm/article/view/749",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Random matrices have simple spectrum.",
                "year": 2017,
                "authors": [
                    "Terence Tao",
                    "Van Vu"
                ],
                "link": "https://doi.org/10.1007/s00493-016-3363-4",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "A Bound on Partitioning Clusters.",
                "year": 2017,
                "authors": [
                    "Daniel Kane 0001",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.37236/6797",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Expanding polynomials over finite fields of large characteristic, and a regularity lemma for definable sets.",
                "year": 2015,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://cdm.ucalgary.ca/cdm/index.php/cdm/article/view/382",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Every odd number greater than 1 is the sum of at most five primes.",
                "year": 2014,
                "authors": [
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1090/S0025-5718-2013-02733-0",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "On Sets Defining Few Ordinary Lines.",
                "year": 2013,
                "authors": [
                    "Ben Joseph Green",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1007/s00454-013-9518-9",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "A nilpotent Freiman dimension lemma.",
                "year": 2013,
                "authors": [
                    "Emmanuel Breuillard",
                    "Ben Green 0001",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1016/j.ejc.2013.05.010",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Noncommutative sets of small doubling.",
                "year": 2013,
                "authors": [
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1016/j.ejc.2013.05.028",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "The Littlewood-Offord problem in high dimensions and a conjecture of Frankl and Fredi.",
                "year": 2012,
                "authors": [
                    "Terence Tao",
                    "Van H. Vu"
                ],
                "link": "https://doi.org/10.1007/s00493-012-2716-x",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "An Incidence Theorem in Higher Dimensions.",
                "year": 2012,
                "authors": [
                    "Jzsef Solymosi",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1007/s00454-012-9420-x",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Deterministic methods to find primes.",
                "year": 2012,
                "authors": [
                    "Terence Tao",
                    "Ernest Croot III",
                    "Harald Helfgott"
                ],
                "link": "https://doi.org/10.1090/S0025-5718-2011-02542-1",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Operator splitting for the KdV equation.",
                "year": 2011,
                "authors": [
                    "Helge Holden",
                    "Kenneth H. Karlsen",
                    "Nils Henrik Risebro",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1090/S0025-5718-2010-02402-0",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Freiman's theorem for solvable groups.",
                "year": 2010,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://cdm.ucalgary.ca/cdm/index.php/cdm/article/view/211",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Sumset and Inverse Sumset Theory for Shannon Entropy.",
                "year": 2010,
                "authors": [
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1017/S0963548309990642",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Smooth analysis of the condition number and the least singular value.",
                "year": 2010,
                "authors": [
                    "Terence Tao",
                    "Van H. Vu"
                ],
                "link": "https://doi.org/10.1090/S0025-5718-2010-02396-8",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Testability and repair of hereditary hypergraph properties.",
                "year": 2010,
                "authors": [
                    "Tim Austin",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1002/rsa.20300",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "A sharp inverse Littlewood-Offord theorem.",
                "year": 2010,
                "authors": [
                    "Terence Tao",
                    "Van H. Vu"
                ],
                "link": "https://doi.org/10.1002/rsa.20327",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "The power of convex relaxation: near-optimal matrix completion.",
                "year": 2010,
                "authors": [
                    "Emmanuel J. Cands",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1109/TIT.2010.2044061",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "The distribution of polynomials over finite fields, with applications to the Gowers norms.",
                "year": 2009,
                "authors": [
                    "Ben Joseph Green",
                    "Terence Tao"
                ],
                "link": "http://cdm.ucalgary.ca/cdm/index.php/cdm/article/view/133",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "The sum-product phenomenon in arbitrary rings.",
                "year": 2009,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://cdm.ucalgary.ca/cdm/index.php/cdm/article/view/160",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Freiman's Theorem in Finite Fields via Extremal Set Theory.",
                "year": 2009,
                "authors": [
                    "Ben Green 0001",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1017/S0963548309009821",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "The Power of Convex Relaxation: Near-Optimal Matrix Completion",
                "year": 2009,
                "authors": [
                    "Emmanuel J. Cands",
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/0903.1476",
                "abstract": "This paper is concerned with the problem of recovering an unknown matrix from a small fraction of its entries. This is known as the matrix completion problem, and comes up in a great number of applications, including the famous Netflix Prize and other similar questions in collaborative filtering. In general, accurate recovery of a matrix from a small number of entries is impossible; but the knowledge that the unknown matrix has low rank radically changes this premise, making the search for solutions meaningful.This paper presents optimality results quantifying the minimum number of entries needed to recover a matrix of rank r exactly by any method whatsoever (the information theoretic limit). More importantly, the paper shows that, under certain incoherence assumptions on the singular vectors of the matrix, recovery is possible by solving a convenient convex program as soon as the number of entries is on the order of the information theoretic limit (up to logarithmic factors). This convex program simply finds, among all matrices consistent with the observed entries, that with minimum nuclear norm. As an example, we show that on the order of nr log(n) samples are needed to recover a random n x n matrix of rank r by any method, and to be sure, nuclear norm minimization succeeds as soon as the number of entries is of the form nr polylog(n).     Comments:51 pages, 12 figuresSubjects:Information Theory (cs.IT)Cite as:arXiv:0903.1476 [cs.IT](or arXiv:0903.1476v1 [cs.IT] for this version)           https://doi.org/10.48550/arXiv.0903.1476Focus to learn more                  arXiv-issued DOI via DataCite"
            },
            {
                "source": "dblp",
                "title": "Product set estimates for non-commutative groups.",
                "year": 2008,
                "authors": [
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1007/s00493-008-2271-7",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Szemerdi's Theorem.",
                "year": 2007,
                "authors": [
                    "Ben Joseph Green",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.4249/scholarpedia.3446",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Szemerdi's regularity lemma revisited.",
                "year": 2006,
                "authors": [
                    "Terence Tao"
                ],
                "link": "http://cdm.ucalgary.ca/cdm/index.php/cdm/article/view/26",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "A Quantitative Ergodic Theory Proof of Szemerdi's Theorem.",
                "year": 2006,
                "authors": [
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.37236/1125",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "A variant of the hypergraph removal lemma.",
                "year": 2006,
                "authors": [
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1016/j.jcta.2005.11.006",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "On random plus/minus 1 matrices: Singularity and determinant.",
                "year": 2006,
                "authors": [
                    "Terence Tao",
                    "Van H. Vu"
                ],
                "link": "https://doi.org/10.1002/rsa.20109",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Robust uncertainty principles: exact signal reconstruction from highly incomplete frequency information.",
                "year": 2006,
                "authors": [
                    "Emmanuel J. Cands",
                    "Justin K. Romberg",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1109/TIT.2005.862083",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?",
                "year": 2006,
                "authors": [
                    "Emmanuel J. Cands",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1109/TIT.2006.885507",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Decoding by linear programming.",
                "year": 2005,
                "authors": [
                    "Emmanuel J. Cands",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1109/TIT.2005.858979",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Decoding by Linear Programming",
                "year": 2005,
                "authors": [
                    "Emmanuel J. Cands",
                    "Terence Tao"
                ],
                "link": "http://arxiv.org/abs/math/0502327",
                "abstract": "This paper considers the classical error correcting problem which is frequently discussed in coding theory. We wish to recover an input vector $f \\in \\R^n$ from corrupted measurements $y = A f + e$. Here, $A$ is an $m$ by $n$ (coding) matrix and $e$ is an arbitrary and unknown vector of errors. Is it possible to recover $f$ exactly from the data $y$? We prove that under suitable conditions on the coding matrix $A$, the input $f$ is the unique solution to the $\\ell_1$-minimization problem ($\\|x\\|_{\\ell_1} := \\sum_i |x_i|$) $$ \\min_{g \\in \\R^n} \\| y - Ag \\|_{\\ell_1} $$ provided that the support of the vector of errors is not too large, $\\|e\\|_{\\ell_0} := |\\{i : e_i \\neq 0\\}| \\le \\rho \\cdot m$ for some $\\rho  0$. In short, $f$ can be recovered exactly by solving a simple convex optimization problem (which one can recast as a linear program). In addition, numerical experiments suggest that this recovery procedure works unreasonably well; $f$ is recovered exactly even in situations where a significant fraction of the output is corrupted."
            },
            {
                "source": "dblp",
                "title": "A Positive Proof of the Littlewood-Richardson Rule using the Octahedron Recurrence.",
                "year": 2004,
                "authors": [
                    "Allen Knutson",
                    "Terence Tao",
                    "Christopher Woodward"
                ],
                "link": "https://doi.org/10.37236/1814",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "A Refined Global Well-Posedness Result for Schrdinger Equations with Derivative.",
                "year": 2002,
                "authors": [
                    "James E. Colliander",
                    "Markus Keel",
                    "Gigliola Staffilani",
                    "Hideo Takaoka",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1137/S0036141001394541",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Global Well-Posedness for Schrdinger Equations with Derivative.",
                "year": 2001,
                "authors": [
                    "James E. Colliander",
                    "Markus Keel",
                    "Gigliola Staffilani",
                    "Hideo Takaoka",
                    "Terence Tao"
                ],
                "link": "https://doi.org/10.1137/S0036141001384387",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information",
                "year": 2006,
                "authors": [
                    "EJ Cands",
                    "J Romberg",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:u5HHmVD_uO8C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Stable signal recovery from incomplete and inaccurate measurements",
                "year": 2006,
                "authors": [
                    "EJ Candes",
                    "JK Romberg",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:9yKSN-GCB0IC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Decoding by linear programming",
                "year": 2005,
                "authors": [
                    "EJ Candes",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:d1gkVwhDpl0C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Near-optimal signal recovery from random projections: Universal encoding strategies?",
                "year": 2006,
                "authors": [
                    "EJ Candes",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:u-x6o8ySG0sC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "The power of convex relaxation: Near-optimal matrix completion",
                "year": 2010,
                "authors": [
                    "EJ Cands",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:zYLM7Y9cAGgC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Endpoint strichartz estimates",
                "year": 1998,
                "authors": [
                    "M Keel",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:qjMakFHDy7sC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Additive combinatorics",
                "year": 2006,
                "authors": [
                    "T Tao",
                    "VH Vu"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:UeHWp8X0CEIC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Nonlinear dispersive equations: local and global analysis",
                "year": 2006,
                "authors": [
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:Y0pCki6q_DkC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Topics in random matrix theory",
                "year": 2012,
                "authors": [
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:08ZZubdj9fEC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "The primes contain arbitrarily long arithmetic progressions",
                "year": 2008,
                "authors": [
                    "B Green",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:IjCSPb-OGe4C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Sharp global well-posedness for KdV and modified KdV on  and ",
                "year": 2003,
                "authors": [
                    "J Colliander",
                    "M Keel",
                    "G Staffilani",
                    "H Takaoka",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:Tyk-4Ss8FVUC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "An introduction to measure theory",
                "year": 2011,
                "authors": [
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:fEOibwPWpKIC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "The honeycomb model of _ {}() tensor products I: Proof of the saturation conjecture",
                "year": 1999,
                "authors": [
                    "A Knutson",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:W7OEmFMy1HYC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "The Princeton companion to mathematics",
                "year": 2010,
                "authors": [
                    "T Gowers",
                    "J Barrow-Green",
                    "I Leader"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:BFa5h04uPMwC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "A sum-product estimate in finite fields, and applications",
                "year": 2004,
                "authors": [
                    "J Bourgain",
                    "N Katz",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:YsMSGLbcyi4C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Global well-posedness and scattering for the energy-critical nonlinear Schrdinger equation in ",
                "year": 2008,
                "authors": [
                    "J Colliander",
                    "M Keel",
                    "G Staffilani",
                    "H Takaoka",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:WF5omc3nYNoC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Random matrices: universality of local eigenvalue statistics",
                "year": 2011,
                "authors": [
                    "T Tao",
                    "V Vu"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:KlAtU1dfN6UC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Random matrices: Universality of ESDs and the circular law",
                "year": 2010,
                "authors": [
                    "T Tao",
                    "V Vu",
                    "M Krishnapur"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:hC7cP41nSMkC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Asymptotics, frequency modulation, and low regularity ill-posedness for canonical defocusing equations",
                "year": 2003,
                "authors": [
                    "M Christ",
                    "J Colliander",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:eQOLeE2rZwMC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Linear equations in primes",
                "year": 2010,
                "authors": [
                    "B Green",
                    "T Tao"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TFx_gLQAAAAJ&citation_for_view=TFx_gLQAAAAJ:4DMP91E08xMC",
                "abstract": null
            }
        ],
        "info": {
            "name": "Terence Tao",
            "affiliations": "Professor of Mathematics, UCLA",
            "email": "Verified email at math.ucla.edu",
            "interests": [
                {
                    "title": "Analysis",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:analysis",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Aanalysis"
                },
                {
                    "title": "Combinatorics",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:combinatorics",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Acombinatorics"
                },
                {
                    "title": "Random Matrix Theory",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:random_matrix_theory",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Arandom_matrix_theory"
                },
                {
                    "title": "PDE",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:pde",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Apde"
                }
            ],
            "thumbnail": "https://scholar.google.com/citations/images/avatar_scholar_128.png",
            "graph": [
                {
                    "year": 2003,
                    "citations": 285
                },
                {
                    "year": 2004,
                    "citations": 411
                },
                {
                    "year": 2005,
                    "citations": 520
                },
                {
                    "year": 2006,
                    "citations": 974
                },
                {
                    "year": 2007,
                    "citations": 1483
                },
                {
                    "year": 2008,
                    "citations": 2323
                },
                {
                    "year": 2009,
                    "citations": 3257
                },
                {
                    "year": 2010,
                    "citations": 4072
                },
                {
                    "year": 2011,
                    "citations": 4792
                },
                {
                    "year": 2012,
                    "citations": 5871
                },
                {
                    "year": 2013,
                    "citations": 6536
                },
                {
                    "year": 2014,
                    "citations": 6988
                },
                {
                    "year": 2015,
                    "citations": 6906
                },
                {
                    "year": 2016,
                    "citations": 6738
                },
                {
                    "year": 2017,
                    "citations": 6634
                },
                {
                    "year": 2018,
                    "citations": 6357
                },
                {
                    "year": 2019,
                    "citations": 5852
                },
                {
                    "year": 2020,
                    "citations": 5566
                },
                {
                    "year": 2021,
                    "citations": 5714
                },
                {
                    "year": 2022,
                    "citations": 5692
                },
                {
                    "year": 2023,
                    "citations": 5778
                },
                {
                    "year": 2024,
                    "citations": 4292
                }
            ],
            "citations": {
                "all": 98758,
                "since_2019": 32925
            },
            "h_index": {
                "all": 112,
                "since_2019": 71
            },
            "i10_index": {
                "all": 366,
                "since_2019": 282
            }
        }
    },
    "Partha Talukdar": {
        "data": [
            {
                "source": "arxiv",
                "title": "Want Answers? A Reddit Inspired Study on How to Pose Questions",
                "year": 2015,
                "authors": [
                    "Danish",
                    "Yogesh Dahiya",
                    "Partha Talukdar"
                ],
                "link": "http://arxiv.org/abs/1512.01768v1",
                "abstract": "Questions form an integral part of our everyday communication, both offlineand online. Getting responses to our questions from others is fundamental tosatisfying our information need and in extending our knowledge boundaries. Aquestion may be represented using various factors such as social, syntactic,semantic, etc. We hypothesize that these factors contribute with varyingdegrees towards getting responses from others for a given question. We performa thorough empirical study to measure effects of these factors using a novelquestion and answer dataset from the website Reddit.com. To the best of ourknowledge, this is the first such analysis of its kind on this important topic.We also use a sparse nonnegative matrix factorization technique toautomatically induce interpretable semantic factors from the question dataset.We also document various patterns on response prediction we observe during ouranalysis in the data. For instance, we found that preference-probing questionsare scantily answered. Our method is robust to capture such latent responsefactors. We hope to make our code and datasets publicly available uponpublication of the paper."
            },
            {
                "source": "arxiv",
                "title": "KGEval: Estimating Accuracy of Automatically Constructed Knowledge\n  Graphs",
                "year": 2016,
                "authors": [
                    "Prakhar Ojha",
                    "Partha Talukdar"
                ],
                "link": "http://arxiv.org/abs/1610.06912v2",
                "abstract": "Automatic construction of large knowledge graphs (KG) by mining web-scaletext datasets has received considerable attention recently. Estimating accuracyof such automatically constructed KGs is a challenging problem due to theirsize and diversity. This important problem has largely been ignored in priorresearch we fill this gap and propose KGEval. KGEval binds facts of a KG usingcoupling constraints and crowdsources the facts that infer correctness of largeparts of the KG. We demonstrate that the objective optimized by KGEval issubmodular and NP-hard, allowing guarantees for our approximation algorithm.Through extensive experiments on real-world datasets, we demonstrate thatKGEval is able to estimate KG accuracy more accurately compared to othercompetitive baselines, while requiring significantly lesser number of humanevaluations."
            },
            {
                "source": "arxiv",
                "title": "Higher-order Relation Schema Induction using Tensor Factorization with\n  Back-off and Aggregation",
                "year": 2017,
                "authors": [
                    "Madhav Nimishakavi",
                    "Partha Talukdar"
                ],
                "link": "http://arxiv.org/abs/1707.01917v2",
                "abstract": "Relation Schema Induction (RSI) is the problem of identifying type signaturesof arguments of relations from unlabeled text. Most of the previous work inthis area have focused only on binary RSI, i.e., inducing only the subject andobject type signatures per relation. However, in practice, many relations arehigh-order, i.e., they have more than two arguments and inducing typesignatures of all arguments is necessary. For example, in the sports domain,inducing a schema win(WinningPlayer, OpponentPlayer, Tournament, Location) ismore informative than inducing just win(WinningPlayer, OpponentPlayer). Werefer to this problem as Higher-order Relation Schema Induction (HRSI). In thispaper, we propose Tensor Factorization with Back-off and Aggregation (TFBA), anovel framework for the HRSI problem. To the best of our knowledge, this is thefirst attempt at inducing higher-order relation schemata from unlabeled text.Using the experimental analysis on three real world datasets, we show how TFBAhelps in dealing with sparsity and induce higher order schemata."
            },
            {
                "source": "arxiv",
                "title": "CANDiS: Coupled & Attention-Driven Neural Distant Supervision",
                "year": 2017,
                "authors": [
                    "Tushar Nagarajan",
                    "Sharmistha",
                    "Partha Talukdar"
                ],
                "link": "http://arxiv.org/abs/1710.09942v1",
                "abstract": "Distant Supervision for Relation Extraction uses heuristically aligned textdata with an existing knowledge base as training data. The unsupervised natureof this technique allows it to scale to web-scale relation extraction tasks, atthe expense of noise in the training data. Previous work has exploredrelationships among instances of the same entity-pair to reduce this noise, butrelationships among instances across entity-pairs have not been fullyexploited. We explore the use of inter-instance couplings based on verb-phraseand entity type similarities. We propose a novel technique, CANDiS, which castsdistant supervision using inter-instance coupling into an end-to-end neuralnetwork model. CANDiS incorporates an attention module at the instance-level tomodel the multi-instance nature of this problem. CANDiS outperforms existingstate-of-the-art techniques on a standard benchmark dataset."
            },
            {
                "source": "arxiv",
                "title": "Reordering Examples Helps during Priming-based Few-Shot Learning",
                "year": 2021,
                "authors": [
                    "Sawan Kumar",
                    "Partha Talukdar"
                ],
                "link": "http://arxiv.org/abs/2106.01751v1",
                "abstract": "The ability to learn from limited data, or few-shot learning, is a desirableand often critical requirement for NLP systems. While many existing methods dopoorly at learning from a handful of examples, large pretrained language modelshave recently been shown to be efficient few-shot learners. One approach tofew-shot learning, which does not require finetuning of model parameters, is toaugment the language model's input with priming text which is typicallyconstructed using task specific descriptions and examples. In this work, wefurther explore priming-based few-shot learning, with focus on using examplesas prompts. We show that presenting examples in the right order is key forgeneralization. We introduce PERO (Prompting with Examples in the Right Order),where we formulate few-shot learning as search over the set of permutations ofthe training examples. We show that PERO can learn to generalize efficientlyusing as few as 10 examples, in contrast to existing approaches. While thenewline token is a natural choice for separating the examples in the prompt, weshow that learning a new separator token can potentially provide further gainsin performance. We demonstrate the effectiveness of the proposed method on thetasks of sentiment classification, natural language inference and factretrieval. Finally, we analyze the learned prompts to reveal novel insights,including the idea that two training examples in the right order alone canprovide competitive performance for sentiment classification and naturallanguage inference."
            },
            {
                "source": "arxiv",
                "title": "NILE : Natural Language Inference with Faithful Natural Language\n  Explanations",
                "year": 2020,
                "authors": [
                    "Sawan Kumar",
                    "Partha Talukdar"
                ],
                "link": "http://arxiv.org/abs/2005.12116v1",
                "abstract": "The recent growth in the popularity and success of deep learning models onNLP classification tasks has accompanied the need for generating some form ofnatural language explanation of the predicted labels. Such generated naturallanguage (NL) explanations are expected to be faithful, i.e., they shouldcorrelate well with the model's internal decision making. In this work, wefocus on the task of natural language inference (NLI) and address the followingquestion: can we build NLI systems which produce labels with high accuracy,while also generating faithful explanations of its decisions? We proposeNatural-language Inference over Label-specific Explanations (NILE), a novel NLImethod which utilizes auto-generated label-specific NL explanations to producelabels along with its faithful explanation. We demonstrate NILE's effectivenessover previously reported methods through automated and human evaluation of theproduced labels and explanations. Our evaluation of NILE also supports theclaim that accurate systems capable of providing testable explanations of theirdecisions can be designed. We discuss the faithfulness of NILE's explanationsin terms of sensitivity of the decisions to the corresponding explanations. Weargue that explicit evaluation of faithfulness, in addition to label andexplanation accuracy, is an important step in evaluating model's explanations.Further, we demonstrate that task-specific probes are necessary to establishsuch sensitivity."
            },
            {
                "source": "arxiv",
                "title": "CESI: Canonicalizing Open Knowledge Bases using Embeddings and Side\n  Information",
                "year": 2019,
                "authors": [
                    "Shikhar Vashishth",
                    "Prince Jain",
                    "Partha Talukdar"
                ],
                "link": "http://arxiv.org/abs/1902.00172v1",
                "abstract": "Open Information Extraction (OpenIE) methods extract (noun phrase, relationphrase, noun phrase) triples from text, resulting in the construction of largeOpen Knowledge Bases (Open KBs). The noun phrases (NPs) and relation phrases insuch Open KBs are not canonicalized, leading to the storage of redundant andambiguous facts. Recent research has posed canonicalization of Open KBs asclustering over manuallydefined feature spaces. Manual feature engineering isexpensive and often sub-optimal. In order to overcome this challenge, wepropose Canonicalization using Embeddings and Side Information (CESI) - a novelapproach which performs canonicalization over learned embeddings of Open KBs.CESI extends recent advances in KB embedding by incorporating relevant NP andrelation phrase side information in a principled manner. Through extensiveexperiments on multiple real-world datasets, we demonstrate CESI'seffectiveness."
            },
            {
                "source": "pubmed",
                "title": "GPU-accelerated connectome discovery at scale.",
                "year": 2022,
                "authors": [
                    "Sreenivasan V",
                    "Kumar S",
                    "Pestilli F",
                    "Talukdar P",
                    "Sridharan D."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/38177824",
                "abstract": "Diffusion magnetic resonance imaging and tractography enable the estimation of anatomical connectivity in the human brain, in vivo. Yet, without ground-truth validation, different tractography algorithms can yield widely varying connectivity estimates. Although streamline pruning techniques mitigate this challenge, slow compute times preclude their use in big-data applications. We present 'Regularized, Accelerated, Linear Fascicle Evaluation' (ReAl-LiFE), a GPU-based implementation of a state-of-the-art streamline pruning algorithm (LiFE), which achieves >100 speedups over previous CPU-based implementations. Leveraging these speedups, we overcome key limitations with LiFE's algorithm to generate sparser and more accurate connectomes. We showcase ReAl-LiFE's ability to estimate connections with superlative test-retest reliability, while outperforming competing approaches. Moreover, we predicted inter-individual variations in multiple cognitive scores with ReAl-LiFE connectome features. We propose ReAl-LiFE as a timely tool, surpassing the state of the art, for accurate discovery of individualized brain connectomes at scale. Finally, our GPU-accelerated implementation of a popular non-negative least-squares optimization algorithm is widely applicable to many real-world problems."
            },
            {
                "source": "pubmed",
                "title": "Turbo-SMT: Parallel Coupled Sparse Matrix-Tensor Factorizations and Applications.",
                "year": 2016,
                "authors": [
                    "Papalexakis EE",
                    "Faloutsos C",
                    "Mitchell TM",
                    "Talukdar PP",
                    "Sidiropoulos ND",
                    "Murphy B."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/27672406",
                "abstract": "How can we correlate the neural activity in the human brain as it responds to typed words, with properties of these terms (like 'edible', 'fits in hand')? In short, we want to find latent variables, that jointly explain both the brain activity, as well as the behavioral responses. This is one of many settings of the Coupled Matrix-Tensor Factorization (CMTF) problem. Can we enhance any CMTF solver, so that it can operate on potentially very large datasets that may not fit in main memory? We introduce Turbo-SMT, a meta-method capable of doing exactly that: it boosts the performance of any CMTF algorithm, produces sparse and interpretable solutions, and parallelizes any CMTF algorithm, producing sparse and interpretable solutions (up to 65 fold). Additionally, we improve upon ALS, the work-horse algorithm for CMTF, with respect to efficiency and robustness to missing values. We apply Turbo-SMT to BrainQ, a dataset consisting of a (nouns, brain voxels, human subjects) tensor and a (nouns, properties) matrix, with coupling along the nouns dimension. Turbo-SMT is able to find meaningful latent variables, as well as to predict brain activity with competitive accuracy. Finally, we demonstrate the generality of Turbo-SMT, by applying it on a Facebook dataset (users, 'friends', wall-postings); there, Turbo-SMT spots spammer-like anomalies."
            },
            {
                "source": "pubmed",
                "title": "Turbo-SMT: Accelerating Coupled Sparse Matrix-Tensor Factorizations by 200.",
                "year": 2014,
                "authors": [
                    "Papalexakis EE",
                    "Faloutsos C",
                    "Mitchell TM",
                    "Talukdar PP",
                    "Sidiropoulos ND",
                    "Murphy B."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/26473087",
                "abstract": "How can we correlate the neural activity in the human brain as it responds to typed words, with properties of these terms (like 'edible', 'fits in hand')? In short, we want to find latent variables, that jointly explain both the brain activity, as well as the behavioral responses. This is one of many settings of the Coupled Matrix-Tensor Factorization (CMTF) problem. Can we accelerate any CMTF solver, so that it runs within a few minutes instead of tens of hours to a day, while maintaining good accuracy? We introduce TURBO-SMT, a meta-method capable of doing exactly that: it boosts the performance of any CMTF algorithm, by up to 200, along with an up to 65 fold increase in sparsity, with comparable accuracy to the baseline. We apply TURBO-SMT to BRAINQ, a dataset consisting of a (nouns, brain voxels, human subjects) tensor and a (nouns, properties) matrix, with coupling along the nouns dimension. TURBO-SMT is able to find meaningful latent variables, as well as to predict brain activity with competitive accuracy."
            },
            {
                "source": "pubmed",
                "title": "Identification of genomic loci regulating grain iron content in aus rice under two irrigation management systems.",
                "year": 2022,
                "authors": [
                    "Talukdar P",
                    "Travis AJ",
                    "Hossain M",
                    "Islam MR",
                    "Norton GJ",
                    "Price AH."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/35866052",
                "abstract": "Iron (Fe) deficiency is one of the common causes of anaemia in humans. Improving grain Fe in rice, therefore, could have a positive impact for humans worldwide, especially for those people who consume rice as a staple food. In this study, 225-269 accessions of the Bengal and Assam Aus Panel (BAAP) were investigated for their accumulation of grain Fe in two consecutive years in a field experiment under alternative wetting and drying (AWD) and continuous flooded (CF) irrigation. AWD reduced straw Fe by 40% and grain Fe by 5.5-13%. Genotype differences accounted for 35% of the variation in grain Fe, while genotype by irrigation interaction accounted for 12% of the variation in straw and grain Fe in year 1, with no significant interactions detected in year 2. Twelve rice accessions were identified as having high grain Fe for both years regardless of irrigation treatment, half of which were from BAAP aus subgroup 3 which prominently comes from Bangladesh. On average, subgroup 3 had higher grain Fe than the other four subgroups of aus. Genome-wide association mapping identified 6 genomic loci controlling natural variation of grain Fe concentration in plants grown under AWD. For one QTL, nicotianamine synthase OsNAS3 is proposed as candidate for controlling natural variation of grain Fe in rice. The BAAP contains three haplotypes of OsNAS3 where one haplotype (detected in 31% of the individuals) increased grain Fe up to 11%. Haplotype analysis of this gene in rice suggests that the ability to detect the QTL is enhanced in the BAAP because the high Fe allele is balanced in aus, unlike indica and japonica subgroups.              Keywords:                    GWA; Iron; QTL; aus; gene; rice."
            },
            {
                "source": "pubmed",
                "title": "Prioritisation of patients awaiting hip and knee arthroplasty: Lower pre-operative EQ-5D is associated with greater improvement in quality of life and joint function.",
                "year": 2022,
                "authors": [
                    "Farrow L",
                    "Redmore J",
                    "Talukdar P",
                    "Clement N",
                    "Ashcroft GP."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/35560766",
                "abstract": "Introduction:                    The COVID-19 pandemic has led to unprecedented delays for those awaiting elective hip and knee arthroplasty. Current demand far exceeds available resource, and therefore it is integral that healthcare resource is fairly rationed to those who need it most. We therefore set out to determine if pre-operative health-related quality of life assessment (HRQoL) could be used to triage arthroplasty waiting lists.              Methods:                    Data regarding demographics, perioperative variables and patient reported outcome measures (PROMs) (pre-operative and 1-year post-operative EuroQOL five dimension (EQ-5D-3L) and Oxford hip and knee scores (OHS/OKS) were retrospectively extracted from electronic patient health records at a large university teaching hospital. Patients were split into two equal groups based on pre-operative EQ-5D TTO scores and compared (Group1 [worse HRQoL] = -0.239 to 0.487; Group2 [better HRQoL] = 0.516-1 [best]).              Results:                    513 patients were included. Patients in Group1 had significantly greater improvement in post-operative EQ-5D-3L scores compared to Group2 (Median 0.67 vs. 0.19; p < 0.0001), as well as greater improvement in OHS/OKS (Mean 22.4 vs. 16.4; p < 0.0001). Those in Group2 were significantly less likely to achieve the EQ-5D-3L minimum clinically important difference (MCID) attainment (OR 0.13, 95%CI 0.07-0.23; p < 0.0001) with a trend towards lower OHS/OKS MCID attainment (OR 0.66, 95%CI 0.37-1.19; p = 0.168). There was no clinically significant difference in length of stay (Median 3-days both groups), and no statistically significant difference in adverse events (30 days and 1 year readmission/reoperation).              Conclusions:                    A pre-operative EQ-5D-3L cut-off of 0.487 for hip and knee arthroplasty prioritisation may help to maximise clinical utility and cost-effectiveness in a limited resource setting post COVID-19.              Keywords:                    arthritics; quality of life."
            },
            {
                "source": "pubmed",
                "title": "Simultaneously uncovering the patterns of brain regions involved in different story reading subprocesses.",
                "year": 2014,
                "authors": [
                    "Wehbe L",
                    "Murphy B",
                    "Talukdar P",
                    "Fyshe A",
                    "Ramdas A",
                    "Mitchell T."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/25426840",
                "abstract": "Story understanding involves many perceptual and cognitive subprocesses, from perceiving individual words, to parsing sentences, to understanding the relationships among the story characters. We present an integrated computational model of reading that incorporates these and additional subprocesses, simultaneously discovering their fMRI signatures. Our model predicts the fMRI activity associated with reading arbitrary text passages, well enough to distinguish which of two story segments is being read with 74% accuracy. This approach is the first to simultaneously track diverse reading subprocesses during complex story processing and predict the detailed neural representation of diverse story features, ranging from visual word properties to the mention of different story characters and different actions they perform. We construct brain representation maps that replicate many results from a wide range of classical studies that focus each on one aspect of language processing and offer new insights on which type of information is processed by different areas involved in language processing. Additionally, this approach is promising for studying individual differences: it can be used to create single subject maps that may potentially be used to measure reading comprehension and diagnose reading disorders."
            },
            {
                "source": "pubmed",
                "title": "QTL-seq reveals a major root-knot nematode resistance locus on chromosome 11 in rice (Oryza sativa L.).",
                "year": 2019,
                "authors": [
                    "Lahari Z",
                    "Ribeiro A",
                    "Talukdar P",
                    "Martin B",
                    "Heidari Z",
                    "Gheysen G",
                    "Price AH",
                    "Shrestha R."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/31274875",
                "abstract": "The root-knot nematode Meloidogyne graminicola is a serious pest in rice affecting production in many rice growing areas. Natural host resistance is an attractive control strategy because the speed of the parasite's life cycle and the broad host range it attacks make other control measures challenging. Although resistance has been found in the domesticated African rice Oryza glaberrima and the wild rice species O. longistaminata, the introgression of resistance genes to Asian rice O. sativa is challenging. Resistance due to a major gene in O. sativa would greatly aid breeding. Recently two accessions resistant to M. graminicola have been identified in a screen of 332 diverse O. sativa cultivars. In this study, these two resistant cultivars, LD 24 (an indica from Sri Lanka) and Khao Pahk Maw (an aus from Thailand), were crossed with a moderately susceptible cultivar, Vialone Nano (a temperate japonica from Italy). Approximately 175 F2 progeny of both populations were screened for susceptibility to M. graminicola infection. Between 20 and 23 individuals with highest and lowest galls per plants were pooled to make susceptible and resistant bulks which were sequenced to conduct bulked segregant analysis using the QTL-seq method. This revealed a nematode resistance locus from 23 Mbp to the bottom of rice chromosome 11 in both crosses suggesting a rare introgression of the same locus is responsible for resistance in both cultivars. While this information can be used in marker-assisted breeding, analysis of available SNP data revealed candidate loci and genes worthy of further investigation for gene identification.              Keywords:                    Bulk segregant analysis; M. graminicola; Nematode resistance genes; O. sativa; QTL-seq."
            },
            {
                "source": "pubmed",
                "title": "Good-Enough Brain Model: Challenges, Algorithms, and Discoveries in Multisubject Experiments.",
                "year": 2014,
                "authors": [
                    "Papalexakis EE",
                    "Fyshe A",
                    "Sidiropoulos ND",
                    "Talukdar PP",
                    "Mitchell TM",
                    "Faloutsos C."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/27442756",
                "abstract": "Given a simple noun such as apple, and a question such as \"Is it edible?,\" what processes take place in the human brain? More specifically, given the stimulus, what are the interactions between (groups of) neurons (also known as functional connectivity) and how can we automatically infer those interactions, given measurements of the brain activity? Furthermore, how does this connectivity differ across different human subjects? In this work, we show that this problem, even though originating from the field of neuroscience, can benefit from big data techniques; we present a simple, novel good-enough brain model, or GeBM in short, and a novel algorithm Sparse-SysId, which are able to effectively model the dynamics of the neuron interactions and infer the functional connectivity. Moreover, GeBM is able to simulate basic psychological phenomena such as habituation and priming (whose definition we provide in the main text). We evaluate GeBM by using real brain data. GeBM produces brain activity patterns that are strikingly similar to the real ones, where the inferred functional connectivity is able to provide neuroscientific insights toward a better understanding of the way that neurons interact with each other, as well as detect regularities and outliers in multisubject brain activity measurements."
            },
            {
                "source": "pubmed",
                "title": "Biallelic and Genome Wide Association Mapping of Germanium Tolerant Loci in Rice (Oryza sativa L.).",
                "year": 2015,
                "authors": [
                    "Talukdar P",
                    "Douglas A",
                    "Price AH",
                    "Norton GJ."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/26356220",
                "abstract": "Rice plants accumulate high concentrations of silicon. Silicon has been shown to be involved in plant growth, high yield, and mitigating biotic and abiotic stresses. However, it has been demonstrated that inorganic arsenic is taken up by rice through silicon transporters under anaerobic conditions, thus the ability to efficiently take up silicon may be considered either a positive or a negative trait in rice. Germanium is an analogue of silicon that produces brown lesions in shoots and leaves, and germanium toxicity has been used to identify mutants in silicon and arsenic transport. In this study, two different genetic mapping methods were performed to determine the loci involved in germanium sensitivity in rice. Genetic mapping in the biparental cross of Bala  Azucena (an F6 population) and a genome wide association (GWA) study with 350 accessions from the Rice Diversity Panel 1 were conducted using 15 M of germanic acid. This identified a number of germanium sensitive loci: some co-localised with previously identified quantitative trait loci (QTL) for tissue silicon or arsenic concentration, none co-localised with Lsi1 or Lsi6, while one single nucleotide polymorphism (SNP) was detected within 200 kb of Lsi2 (these are genes known to transport silicon, whose identity was discovered using germanium toxicity). However, examining candidate genes that are within the genomic region of the loci detected above reveals genes homologous to both Lsi1 and Lsi2, as well as a number of other candidate genes, which are discussed."
            },
            {
                "source": "pubmed",
                "title": "Interpretable Semantic Vectors from a Joint Model of Brain- and Text-Based Meaning.",
                "year": 2014,
                "authors": [
                    "Fyshe A",
                    "Talukdar PP",
                    "Murphy B",
                    "Mitchell TM."
                ],
                "link": "https://pubmed.ncbi.nlm.nih.gov/26166940",
                "abstract": "Vector space models (VSMs) represent word meanings as points in a high dimensional space. VSMs are typically created using a large text corpora, and so represent word semantics as observed in text. We present a new algorithm (JNNSE) that can incorporate a measure of semantics not previously used to create VSMs: brain activation data recorded while people read words. The resulting model takes advantage of the complementary strengths and weaknesses of corpus and brain activation data to give a more complete representation of semantics. Evaluations show that the model 1) matches a behavioral measure of semantics more closely, 2) can be used to predict corpus data for unseen words and 3) has predictive power that generalizes across brain imaging technologies and across subjects. We believe that the model is thus a more faithful representation of mental vocabularies."
            },
            {
                "source": "acmdl",
                "title": "Graph-based Deep Learning in Natural Language Processing",
                "year": 2020,
                "authors": [
                    "Shikhar Vashishth",
                    "Naganand Yadati",
                    "Partha Talukdar"
                ],
                "link": "https://dl.acm.org/doi/10.1145/3371158.3371232",
                "abstract": "This tutorial aims to introduce recent advances in graph-based deep learning techniques such as Graph Convolutional Networks (GCNs) for Natural Language Processing (NLP). It provides a brief introduction to deep learning methods on non-Euclidean domains ..."
            },
            {
                "source": "acmdl",
                "title": "NHP: Neural Hypergraph Link Prediction",
                "year": 2020,
                "authors": [
                    "Naganand Yadati",
                    "Vikram Nitin",
                    "Madhav Nimishakavi",
                    "Prateek Yadav",
                    "Anand Louis",
                    "Partha Talukdar"
                ],
                "link": "https://dl.acm.org/doi/10.1145/3340531.3411870",
                "abstract": "Link prediction insimple graphs is a fundamental problem in which new links between vertices are predicted based on the observed structure of the graph. However, in many real-world applications, there is a need to model relationships among vertices that ..."
            },
            {
                "source": "acmdl",
                "title": "CESI",
                "year": 2018,
                "authors": [
                    "Shikhar Vashishth",
                    "Prince Jain",
                    "Partha Talukdar"
                ],
                "link": "https://dl.acm.org/doi/10.1145/3178876.3186030",
                "abstract": "Open Information Extraction (OpenIE) methods extract (noun phrase, relation phrase, noun phrase) triples from text, resulting in the construction of large Open Knowledge Bases (Open KBs). The noun phrases (NPs) and relation phrases in such Open KBs are ..."
            },
            {
                "source": "acmdl",
                "title": "Inductive Framework for Multi-Aspect Streaming Tensor Completion with Side Information",
                "year": 2018,
                "authors": [
                    "Madhav Nimishakavi",
                    "Bamdev Mishra",
                    "Manish Gupta",
                    "Partha Talukdar"
                ],
                "link": "https://dl.acm.org/doi/10.1145/3269206.3271713",
                "abstract": "Low rank tensor completion is a well studied problem and has applications in various fields. However, in many real world applications the data is dynamic, i.e., new data arrives at different time intervals. As a result, the tensors used to represent the ..."
            },
            {
                "source": "acmdl",
                "title": "Walking with PACE - Personalized and Automated Coaching Engine",
                "year": 2022,
                "authors": [
                    "Madhurima Vardhan",
                    "Narayan Hegde",
                    "Srujana Merugu",
                    "Shantanu Prabhat",
                    "Deepak Nathani",
                    "Martin Seneviratne",
                    "Nur Muhammad",
                    "Pranay Reddy",
                    "Sriram Lakshminarasimhan",
                    "Rahul Singh",
                    "Karina Lorenzana",
                    "Eshan Motwani",
                    "Partha Talukdar",
                    "Aravindan Raghuveer"
                ],
                "link": "https://dl.acm.org/doi/10.1145/3503252.3531301",
                "abstract": "We design and implement a personalized and automated physical activity coaching engine, PACE, which uses the Foggs behavioral model (FBM) to engage users in mini-conversation based coaching sessions. It is a chat-based nudge assistant that can boost (..."
            },
            {
                "source": "acmdl",
                "title": "Automatic Gloss Finding for a Knowledge Base using Ontological Constraints",
                "year": 2015,
                "authors": [
                    "Bhavana Dalvi",
                    "Einat Minkov",
                    "Partha P. Talukdar",
                    "William W. Cohen"
                ],
                "link": "https://dl.acm.org/doi/10.1145/2684822.2685288",
                "abstract": "While there has been much research on automatically constructing structured Knowledge Bases (KBs), most of it has focused on generating facts to populate a KB. However, a useful KB must go beyond facts. For example, glosses (short natural language ..."
            },
            {
                "source": "acmdl",
                "title": "AKBC 2013",
                "year": 2013,
                "authors": [
                    "Fabian M. Suchanek",
                    "Sebastian Riedel",
                    "Sameer Singh",
                    "Partha P. Talukdar"
                ],
                "link": "https://dl.acm.org/doi/10.1145/2505515.2505806",
                "abstract": "The AKBC 2013 workshop aims to be a venue of excellence and vision in the area of knowledge base construction. This year's workshop will feature keynotes by ten leading researchers in the field, including from Google, Microsoft, Stanford, and CMU. The ..."
            },
            {
                "source": "acmdl",
                "title": "Selecting corpus-semantic models for neurolinguistic decoding",
                "year": 2012,
                "authors": [
                    "Brian Murphy",
                    "Partha Talukdar",
                    "Tom Mitchell"
                ],
                "link": "https://dl.acm.org/doi/10.5555/2387636.2387658",
                "abstract": "Neurosemantics aims to learn the mapping between concepts and the neural activity which they elicit during neuroimaging experiments. Different approaches have been used to represent individual concepts, but current state-of-the-art techniques require ..."
            },
            {
                "source": "nature",
                "title": "GPU-accelerated connectome discovery at scale",
                "year": 2022,
                "authors": [
                    "Varsha Sreenivasan ORCID: orcid.org/0000-0003-3225-70571",
                    "Sawan Kumar2",
                    "Franco Pestilli3",
                    "Partha Talukdar24",
                    "Devarajan Sridharan ORCID: orcid.org/0000-0003-1998-901814"
                ],
                "link": "https://www.nature.com/articles/s43588-022-00250-z",
                "abstract": "Diffusion magnetic resonance imaging and tractography enable the estimation of anatomical connectivity in the human brain, in vivo. Yet, without ground-truth validation, different tractography algorithms can yield widely varying connectivity estimates. Although streamline pruning techniques mitigate this challenge, slow compute times preclude their use in big-data applications. We present Regularized, Accelerated, Linear Fascicle Evaluation (ReAl-LiFE), a GPU-based implementation of a state-of-the-art streamline pruning algorithm (LiFE), which achieves >100 speedups over previous CPU-based implementations. Leveraging these speedups, we overcome key limitations with LiFEs algorithm to generate sparser and more accurate connectomes. We showcase ReAl-LiFEs ability to estimate connections with superlative testretest reliability, while outperforming competing approaches. Moreover, we predicted inter-individual variations in multiple cognitive scores with ReAl-LiFE connectome features. We propose ReAl-LiFE as a timely tool, surpassing the state of the art, for accurate discovery of individualized brain connectomes at scale. Finally, our GPU-accelerated implementation of a popular non-negative least-squares optimization algorithm is widely applicable to many real-world problems."
            },
            null,
            null,
            {
                "source": "dblp",
                "title": "GPU-accelerated connectome discovery at scale.",
                "year": 2022,
                "authors": [
                    "Varsha Sreenivasan",
                    "Sawan Kumar",
                    "Franco Pestilli",
                    "Partha P. Talukdar",
                    "Devarajan Sridharan"
                ],
                "link": "https://doi.org/10.1038/s43588-022-00250-z",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Overlap-based Vocabulary Generation Improves Cross-lingual Transfer Among Related Languages.",
                "year": 2022,
                "authors": [
                    "Vaidehi Patil",
                    "Partha P. Talukdar",
                    "Sunita Sarawagi"
                ],
                "link": "https://doi.org/10.48550/arXiv.2203.01976",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Evaluating Inclusivity, Equity, and Accessibility of NLP Technology: A Case Study for Indian Languages.",
                "year": 2022,
                "authors": [
                    "Simran Khanuja",
                    "Sebastian Ruder",
                    "Partha P. Talukdar"
                ],
                "link": "https://doi.org/10.48550/arXiv.2205.12676",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Parameter-Efficient Finetuning for Robust Continual Multilingual Learning.",
                "year": 2022,
                "authors": [
                    "Kartikeya Badola",
                    "Shachi Dave",
                    "Partha P. Talukdar"
                ],
                "link": "https://doi.org/10.48550/arXiv.2209.06767",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Re-contextualizing Fairness in NLP: The Case of India.",
                "year": 2022,
                "authors": [
                    "Shaily Bhatt",
                    "Sunipa Dev",
                    "Partha P. Talukdar",
                    "Shachi Dave",
                    "Vinodkumar Prabhakaran"
                ],
                "link": "https://doi.org/10.48550/arXiv.2209.12226",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "TwiRGCN: Temporally Weighted Graph Convolution for Question Answering over Temporal Knowledge Graphs.",
                "year": 2022,
                "authors": [
                    "Aditya Sharma",
                    "Apoorv Saxena",
                    "Chitrank Gupta",
                    "Seyed Mehran Kazemi",
                    "Partha P. Talukdar",
                    "Soumen Chakrabarti"
                ],
                "link": "https://doi.org/10.48550/arXiv.2210.06281",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Bootstrapping Multilingual Semantic Parsers using Large Language Models.",
                "year": 2022,
                "authors": [
                    "Abhijeet Awasthi",
                    "Nitish Gupta",
                    "Bidisha Samanta",
                    "Shachi Dave",
                    "Sunita Sarawagi",
                    "Partha P. Talukdar"
                ],
                "link": "https://doi.org/10.48550/arXiv.2210.07313",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Cultural Re-contextualization of Fairness Research in Language Technologies in India.",
                "year": 2022,
                "authors": [
                    "Shaily Bhatt",
                    "Sunipa Dev",
                    "Partha P. Talukdar",
                    "Shachi Dave",
                    "Vinodkumar Prabhakaran"
                ],
                "link": "https://doi.org/10.48550/arXiv.2211.11206",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "MuRIL: Multilingual Representations for Indian Languages.",
                "year": 2021,
                "authors": [
                    "Simran Khanuja",
                    "Diksha Bansal",
                    "Sarvesh Mehtani",
                    "Savya Khosla",
                    "Atreyee Dey",
                    "Balaji Gopalan",
                    "Dilip Kumar Margam",
                    "Pooja Aggarwal",
                    "Rajiv Teja Nagipogu",
                    "Shachi Dave",
                    "Shruti Gupta",
                    "Subhash Chandra Bose Gali",
                    "Vish Subramanian",
                    "Partha P. Talukdar"
                ],
                "link": "https://arxiv.org/abs/2103.10730",
                "abstract": "India is a multilingual society with 1369 rationalized languages and dialects being spoken across the country (INDIA, 2011). Of these, the 22 scheduled languages have a staggering total of 1.17 billion speakers and 121 languages have more than 10,000 speakers (INDIA, 2011). India also has the second largest (and an ever growing) digital footprint (Statista, 2020). Despite this, today's state-of-the-art multilingual systems perform suboptimally on Indian (IN) languages. This can be explained by the fact that multilingual language models (LMs) are often trained on 100+ languages together, leading to a small representation of IN languages in their vocabulary and training data. Multilingual LMs are substantially less effective in resource-lean scenarios (Wu and Dredze, 2020; Lauscher et al., 2020), as limited data doesn't help capture the various nuances of a language. One also commonly observes IN language text transliterated to Latin or code-mixed with English, especially in informal settings (for example, on social media platforms) (Rijhwani et al., 2017). This phenomenon is not adequately handled by current state-of-the-art multilingual LMs. To address the aforementioned gaps, we propose MuRIL, a multilingual LM specifically built for IN languages. MuRIL is trained on significantly large amounts of IN text corpora only. We explicitly augment monolingual text corpora with both translated and transliterated document pairs, that serve as supervised cross-lingual signals in training. MuRIL significantly outperforms multilingual BERT (mBERT) on all tasks in the challenging cross-lingual XTREME benchmark (Hu et al., 2020). We also present results on transliterated (native to Latin script) test sets of the chosen datasets and demonstrate the efficacy of MuRIL in handling transliterated data."
            },
            {
                "source": "dblp",
                "title": "Question Answering Over Temporal Knowledge Graphs.",
                "year": 2021,
                "authors": [
                    "Apoorv Saxena",
                    "Soumen Chakrabarti",
                    "Partha P. Talukdar"
                ],
                "link": "https://arxiv.org/abs/2106.01515",
                "abstract": "Temporal Knowledge Graphs (Temporal KGs) extend regular Knowledge Graphs by providing temporal scopes (start and end times) on each edge in the KG. While Question Answering over KG (KGQA) has received some attention from the research community, QA over Temporal KGs (Temporal KGQA) is a relatively unexplored area. Lack of broad coverage datasets has been another factor limiting progress in this area. We address this challenge by presenting CRONQUESTIONS, the largest known Temporal KGQA dataset, clearly stratified into buckets of structural complexity. CRONQUESTIONS expands the only known previous dataset by a factor of 340x. We find that various state-of-the-art KGQA methods fall far short of the desired performance on this new dataset. In response, we also propose CRONKGQA, a transformer-based solution that exploits recent advances in Temporal KG embeddings, and achieves performance superior to all baselines, with an increase of 120% in accuracy over the next best performing method. Through extensive experiments, we give detailed insights into the workings of CRONKGQA, as well as situations where significant further improvements appear possible. In addition to the dataset, we have released our code as well."
            },
            {
                "source": "dblp",
                "title": "Reordering Examples Helps during Priming-based Few-Shot Learning.",
                "year": 2021,
                "authors": [
                    "Sawan Kumar",
                    "Partha P. Talukdar"
                ],
                "link": "https://arxiv.org/abs/2106.01751",
                "abstract": "The ability to learn from limited data, or few-shot learning, is a desirable and often critical requirement for NLP systems. While many existing methods do poorly at learning from a handful of examples, large pretrained language models have recently been shown to be efficient few-shot learners. One approach to few-shot learning, which does not require finetuning of model parameters, is to augment the language model's input with priming text which is typically constructed using task specific descriptions and examples. In this work, we further explore priming-based few-shot learning, with focus on using examples as prompts. We show that presenting examples in the right order is key for generalization. We introduce PERO (Prompting with Examples in the Right Order), where we formulate few-shot learning as search over the set of permutations of the training examples. We show that PERO can learn to generalize efficiently using as few as 10 examples, in contrast to existing approaches. While the newline token is a natural choice for separating the examples in the prompt, we show that learning a new separator token can potentially provide further gains in performance. We demonstrate the effectiveness of the proposed method on the tasks of sentiment classification, natural language inference and fact retrieval. Finally, we analyze the learned prompts to reveal novel insights, including the idea that two training examples in the right order alone can provide competitive performance for sentiment classification and natural language inference."
            },
            {
                "source": "dblp",
                "title": "MergeDistill: Merging Pre-trained Language Models using Distillation.",
                "year": 2021,
                "authors": [
                    "Simran Khanuja",
                    "Melvin Johnson",
                    "Partha P. Talukdar"
                ],
                "link": "https://arxiv.org/abs/2106.02834",
                "abstract": "Pre-trained multilingual language models (LMs) have achieved state-of-the-art results in cross-lingual transfer, but they often lead to an inequitable representation of languages due to limited capacity, skewed pre-training data, and sub-optimal vocabularies. This has prompted the creation of an ever-growing pre-trained model universe, where each model is trained on large amounts of language or domain specific data with a carefully curated, linguistically informed vocabulary. However, doing so brings us back full circle and prevents one from leveraging the benefits of multilinguality. To address the gaps at both ends of the spectrum, we propose MergeDistill, a framework to merge pre-trained LMs in a way that can best leverage their assets with minimal dependencies, using task-agnostic knowledge distillation. We demonstrate the applicability of our framework in a practical setting by leveraging pre-existing teacher LMs and training student LMs that perform competitively with or even outperform teacher LMs trained on several orders of magnitude more data and with a fixed model capacity. We also highlight the importance of teacher selection and its impact on student model performance."
            },
            {
                "source": "dblp",
                "title": "Exploiting Language Relatedness for Low Web-Resource Language Model Adaptation: An Indic Languages Study.",
                "year": 2021,
                "authors": [
                    "Yash Khemchandani",
                    "Sarvesh Mehtani",
                    "Vaidehi Patil",
                    "Abhijeet Awasthi",
                    "Partha P. Talukdar",
                    "Sunita Sarawagi"
                ],
                "link": "https://arxiv.org/abs/2106.03958",
                "abstract": "Recent research in multilingual language models (LM) has demonstrated their ability to effectively handle multiple languages in a single model. This holds promise for low web-resource languages (LRL) as multilingual models can enable transfer of supervision from high resource languages to LRLs. However, incorporating a new language in an LM still remains a challenge, particularly for languages with limited corpora and in unseen scripts. In this paper we argue that relatedness among languages in a language family may be exploited to overcome some of the corpora limitations of LRLs, and propose RelateLM. We focus on Indian languages, and exploit relatedness along two dimensions: (1) script (since many Indic scripts originated from the Brahmic script), and (2) sentence structure. RelateLM uses transliteration to convert the unseen script of limited LRL text into the script of a Related Prominent Language (RPL) (Hindi in our case). While exploiting similar sentence structures, RelateLM utilizes readily available bilingual dictionaries to pseudo translate RPL text into LRL corpora. Experiments on multiple real-world benchmark datasets provide validation to our hypothesis that using a related language as pivot, along with transliteration and pseudo translation based data augmentation, can be an effective way to adapt LMs for LRLs, rather than direct training or pivoting through English."
            },
            {
                "source": "dblp",
                "title": "OKGIT: Open Knowledge Graph Link Prediction with Implicit Types.",
                "year": 2021,
                "authors": [
                    "Chandrahas",
                    "Partha Pratim Talukdar"
                ],
                "link": "https://arxiv.org/abs/2106.12806",
                "abstract": "Open Knowledge Graphs (OpenKG) refer to a set of (head noun phrase, relation phrase, tail noun phrase) triples such as (tesla, return to, new york) extracted from a corpus using OpenIE tools. While OpenKGs are easy to bootstrap for a domain, they are very sparse and far from being directly usable in an end task. Therefore, the task of predicting new facts, i.e., link prediction, becomes an important step while using these graphs in downstream tasks such as text comprehension, question answering, and web search query recommendation. Learning embeddings for OpenKGs is one approach for link prediction that has received some attention lately. However, on careful examination, we found that current OpenKG link prediction algorithms often predict noun phrases (NPs) with incompatible types for given noun and relation phrases. We address this problem in this work and propose OKGIT that improves OpenKG link prediction using novel type compatibility score and type regularization. With extensive experiments on multiple datasets, we show that the proposed method achieves state-of-the-art performance while producing type compatible NPs in the link prediction task."
            },
            {
                "source": "dblp",
                "title": "Multilingual Fact Linking.",
                "year": 2021,
                "authors": [
                    "Keshav Kolluru",
                    "Martin Rezk",
                    "Pat Verga",
                    "William W. Cohen",
                    "Partha P. Talukdar"
                ],
                "link": "https://arxiv.org/abs/2109.14364",
                "abstract": "Knowledge-intensive NLP tasks can benefit from linking natural language text with facts from a Knowledge Graph (KG). Although facts themselves are language-agnostic, the fact labels (i.e., language-specific representation of the fact) in the KG are often present only in a few languages. This makes it challenging to link KG facts to sentences in languages other than the limited set of languages. To address this problem, we introduce the task of Multilingual Fact Linking (MFL) where the goal is to link fact expressed in a sentence to corresponding fact in the KG, even when the fact label in the KG is not available in the language of the sentence. To facilitate research in this area, we present a new evaluation dataset, IndicLink. This dataset contains 11,293 linked WikiData facts and 6,429 sentences spanning English and six Indian languages. We propose a Retrieval+Generation model, ReFCoG, that can scale to millions of KG facts by combining Dual Encoder based retrieval with a Seq2Seq based generation model which is constrained to output only valid KG facts. ReFCoG outperforms standard Retrieval+Re-ranking models by 10.7 pts in Precision@1. In spite of this gain, the model achieves an overall score of 52.1, showing ample scope for improvement in the task.ReFCoG code and IndicLink data are available at this https URL"
            },
            {
                "source": "dblp",
                "title": "Syntax-Guided Controlled Generation of Paraphrases.",
                "year": 2020,
                "authors": [
                    "Ashutosh Kumar",
                    "Kabir Ahuja",
                    "Raghuram Vadapalli",
                    "Partha P. Talukdar"
                ],
                "link": "https://doi.org/10.1162/tacl_a_00318",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Syntax-guided Controlled Generation of Paraphrases.",
                "year": 2020,
                "authors": [
                    "Ashutosh Kumar",
                    "Kabir Ahuja",
                    "Raghuram Vadapalli",
                    "Partha P. Talukdar"
                ],
                "link": "https://arxiv.org/abs/2005.08417",
                "abstract": "Given a sentence (e.g., \"I like mangoes\") and a constraint (e.g., sentiment flip), the goal of controlled text generation is to produce a sentence that adapts the input sentence to meet the requirements of the constraint (e.g., \"I hate mangoes\"). Going beyond such simple constraints, recent works have started exploring the incorporation of complex syntactic-guidance as constraints in the task of controlled paraphrase generation. In these methods, syntactic-guidance is sourced from a separate exemplar sentence. However, these prior works have only utilized limited syntactic information available in the parse tree of the exemplar sentence. We address this limitation in the paper and propose Syntax Guided Controlled Paraphraser (SGCP), an end-to-end framework for syntactic paraphrase generation. We find that SGCP can generate syntax conforming sentences while not compromising on relevance. We perform extensive automated and human evaluations over multiple real-world English language datasets to demonstrate the efficacy of SGCP over state-of-the-art baselines. To drive future research, we have made SGCP's source code available"
            },
            {
                "source": "dblp",
                "title": "P-SIF: Document Embeddings Using Partition Averaging.",
                "year": 2020,
                "authors": [
                    "Vivek Gupta 0001",
                    "Ankit Saw",
                    "Pegah Nokhiz",
                    "Praneeth Netrapalli",
                    "Piyush Rai",
                    "Partha P. Talukdar"
                ],
                "link": "https://arxiv.org/abs/2005.09069",
                "abstract": "Simple weighted averaging of word vectors often yields effective representations for sentences which outperform sophisticated seq2seq neural models in many tasks. While it is desirable to use the same method to represent documents as well, unfortunately, the effectiveness is lost when representing long documents involving multiple sentences. One of the key reasons is that a longer document is likely to contain words from many different topics; hence, creating a single vector while ignoring all the topical structure is unlikely to yield an effective document representation. This problem is less acute in single sentences and other short text fragments where the presence of a single topic is most likely. To alleviate this problem, we present P-SIF, a partitioned word averaging model to represent long documents. P-SIF retains the simplicity of simple weighted word averaging while taking a document's topical structure into account. In particular, P-SIF learns topic-specific vectors from a document and finally concatenates them all to represent the overall document. We provide theoretical justifications on the correctness of P-SIF. Through a comprehensive set of experiments, we demonstrate P-SIF's effectiveness compared to simple weighted averaging and many other baselines."
            },
            {
                "source": "dblp",
                "title": "NILE : Natural Language Inference with Faithful Natural Language Explanations.",
                "year": 2020,
                "authors": [
                    "Sawan Kumar",
                    "Partha P. Talukdar"
                ],
                "link": "https://arxiv.org/abs/2005.12116",
                "abstract": "The recent growth in the popularity and success of deep learning models on NLP classification tasks has accompanied the need for generating some form of natural language explanation of the predicted labels. Such generated natural language (NL) explanations are expected to be faithful, i.e., they should correlate well with the model's internal decision making. In this work, we focus on the task of natural language inference (NLI) and address the following question: can we build NLI systems which produce labels with high accuracy, while also generating faithful explanations of its decisions? We propose Natural-language Inference over Label-specific Explanations (NILE), a novel NLI method which utilizes auto-generated label-specific NL explanations to produce labels along with its faithful explanation. We demonstrate NILE's effectiveness over previously reported methods through automated and human evaluation of the produced labels and explanations. Our evaluation of NILE also supports the claim that accurate systems capable of providing testable explanations of their decisions can be designed. We discuss the faithfulness of NILE's explanations in terms of sensitivity of the decisions to the corresponding explanations. We argue that explicit evaluation of faithfulness, in addition to label and explanation accuracy, is an important step in evaluating model's explanations. Further, we demonstrate that task-specific probes are necessary to establish such sensitivity."
            },
            {
                "source": "dblp",
                "title": "Efficient and Distributed Generalized Canonical Correlation Analysis for Big Multiview Data.",
                "year": 2019,
                "authors": [
                    "Xiao Fu 0001",
                    "Kejun Huang",
                    "Evangelos E. Papalexakis",
                    "Hyun Ah Song",
                    "Partha P. Talukdar",
                    "Nicholas D. Sidiropoulos",
                    "Christos Faloutsos",
                    "Tom M. Mitchell"
                ],
                "link": "https://doi.org/10.1109/TKDE.2018.2875908",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Confidence-based Graph Convolutional Networks for Semi-Supervised Learning.",
                "year": 2019,
                "authors": [
                    "Shikhar Vashishth",
                    "Prateek Yadav",
                    "Manik Bhandari",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1901.08255",
                "abstract": "Predicting properties of nodes in a graph is an important problem with applications in a variety of domains. Graph-based Semi-Supervised Learning (SSL) methods aim to address this problem by labeling a small subset of the nodes as seeds and then utilizing the graph structure to predict label scores for the rest of the nodes in the graph. Recently, Graph Convolutional Networks (GCNs) have achieved impressive performance on the graph-based SSL task. In addition to label scores, it is also desirable to have confidence scores associated with them. Unfortunately, confidence estimation in the context of GCN has not been previously explored. We fill this important gap in this paper and propose ConfGCN, which estimates labels scores along with their confidences jointly in GCN-based setting. ConfGCN uses these estimated confidences to determine the influence of one node on another during neighborhood aggregation, thereby acquiring anisotropic capabilities. Through extensive analysis and experiments on standard benchmarks, we find that ConfGCN is able to outperform state-of-the-art baselines. We have made ConfGCN's source code available to encourage reproducible research."
            },
            {
                "source": "dblp",
                "title": "CESI: Canonicalizing Open Knowledge Bases using Embeddings and Side Information.",
                "year": 2019,
                "authors": [
                    "Shikhar Vashishth",
                    "Prince Jain",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1902.00172",
                "abstract": "Open Information Extraction (OpenIE) methods extract (noun phrase, relation phrase, noun phrase) triples from text, resulting in the construction of large Open Knowledge Bases (Open KBs). The noun phrases (NPs) and relation phrases in such Open KBs are not canonicalized, leading to the storage of redundant and ambiguous facts. Recent research has posed canonicalization of Open KBs as clustering over manuallydefined feature spaces. Manual feature engineering is expensive and often sub-optimal. In order to overcome this challenge, we propose Canonicalization using Embeddings and Side Information (CESI) - a novel approach which performs canonicalization over learned embeddings of Open KBs. CESI extends recent advances in KB embedding by incorporating relevant NP and relation phrase side information in a principled manner. Through extensive experiments on multiple real-world datasets, we demonstrate CESI's effectiveness."
            },
            {
                "source": "dblp",
                "title": "Dating Documents using Graph Convolution Networks.",
                "year": 2019,
                "authors": [
                    "Shikhar Vashishth",
                    "Shib Sankar Dasgupta",
                    "Swayambhu Nath Ray",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1902.00175",
                "abstract": "Document date is essential for many important tasks, such as document retrieval, summarization, event detection, etc. While existing approaches for these tasks assume accurate knowledge of the document date, this is not always available, especially for arbitrary documents from the Web. Document Dating is a challenging problem which requires inference over the temporal structure of the document. Prior document dating systems have largely relied on handcrafted features while ignoring such document internal structures. In this paper, we propose NeuralDater, a Graph Convolutional Network (GCN) based document dating approach which jointly exploits syntactic and temporal graph structures of document in a principled way. To the best of our knowledge, this is the first application of deep learning for the problem of document dating. Through extensive experiments on real-world datasets, we find that NeuralDater significantly outperforms state-of-the-art baseline by 19% absolute (45% relative) accuracy points."
            },
            {
                "source": "dblp",
                "title": "AD3: Attentive Deep Document Dater.",
                "year": 2019,
                "authors": [
                    "Swayambhu Nath Ray",
                    "Shib Sankar Dasgupta",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1902.02161",
                "abstract": "Knowledge of the creation date of documents facilitates several tasks such as summarization, event extraction, temporally focused information extraction etc. Unfortunately, for most of the documents on the Web, the time-stamp metadata is either missing or can't be trusted. Thus, predicting creation time from document content itself is an important task. In this paper, we propose Attentive Deep Document Dater (AD3), an attention-based neural document dating system which utilizes both context and temporal information in documents in a flexible and principled manner. We perform extensive experimentation on multiple real-world datasets to demonstrate the effectiveness of AD3 over neural and non-neural baselines."
            },
            {
                "source": "dblp",
                "title": "Relating Simple Sentence Representations in Deep Neural Networks and the Brain.",
                "year": 2019,
                "authors": [
                    "Sharmistha Jat",
                    "Hao Tang",
                    "Partha P. Talukdar",
                    "Tom Michael Mitchell"
                ],
                "link": "http://arxiv.org/abs/1906.11861",
                "abstract": "What is the relationship between sentence representations learned by deep recurrent models against those encoded by the brain? Is there any correspondence between hidden layers of these recurrent models and brain regions when processing sentences? Can these deep models be used to synthesize brain data which can then be utilized in other extrinsic tasks? We investigate these questions using sentences with simple syntax and semantics (e.g., The bone was eaten by the dog.). We consider multiple neural network architectures, including recently proposed ELMo and BERT. We use magnetoencephalography (MEG) brain recording data collected from human subjects when they were reading these simple sentences.Overall, we find that BERT's activations correlate the best with MEG brain data. We also find that the deep network representation can be used to generate brain data from new sentences to augment existing brain data.To the best of our knowledge, this is the first work showing that the MEG brain recording when reading a word in a sentence can be used to distinguish earlier words in the sentence. Our exploration is also the first to use deep neural network representations to generate synthetic brain data and to show that it helps in improving subsequent stimuli decoding task accuracy.     Comments:Association for Computational Linguistics (ACL) 2019Subjects:Computation and Language (cs.CL)Cite as:arXiv:1906.11861 [cs.CL](or arXiv:1906.11861v1 [cs.CL] for this version)           https://doi.org/10.48550/arXiv.1906.11861Focus to learn more                  arXiv-issued DOI via DataCite"
            },
            {
                "source": "dblp",
                "title": "InteractE: Improving Convolution-based Knowledge Graph Embeddings by Increasing Feature Interactions.",
                "year": 2019,
                "authors": [
                    "Shikhar Vashishth",
                    "Soumya Sanyal 0001",
                    "Vikram Nitin",
                    "Nilesh Agrawal",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1911.00219",
                "abstract": "Most existing knowledge graphs suffer from incompleteness, which can be alleviated by inferring missing links based on known facts. One popular way to accomplish this is to generate low-dimensional embeddings of entities and relations, and use these to make inferences. ConvE, a recently proposed approach, applies convolutional filters on 2D reshapings of entity and relation embeddings in order to capture rich interactions between their components. However, the number of interactions that ConvE can capture is limited. In this paper, we analyze how increasing the number of these interactions affects link prediction performance, and utilize our observations to propose InteractE. InteractE is based on three key ideas -- feature permutation, a novel feature reshaping, and circular convolution. Through extensive experiments, we find that InteractE outperforms state-of-the-art convolutional link prediction baselines on FB15k-237. Further, InteractE achieves an MRR score that is 9%, 7.5%, and 23% better than ConvE on the FB15k-237, WN18RR and YAGO3-10 datasets respectively. The results validate our central hypothesis -- that increasing feature interaction is beneficial to link prediction performance. We make the source code of InteractE available to encourage reproducible research."
            },
            {
                "source": "dblp",
                "title": "Composition-based Multi-Relational Graph Convolutional Networks.",
                "year": 2019,
                "authors": [
                    "Shikhar Vashishth",
                    "Soumya Sanyal 0001",
                    "Vikram Nitin",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1911.03082",
                "abstract": "Graph Convolutional Networks (GCNs) have recently been shown to be quite successful in modeling graph-structured data. However, the primary focus has been on handling simple undirected graphs. Multi-relational graphs are a more general and prevalent form of graphs where each edge has a label and direction associated with it. Most of the existing approaches to handle such graphs suffer from over-parameterization and are restricted to learning representations of nodes only. In this paper, we propose CompGCN, a novel Graph Convolutional framework which jointly embeds both nodes and relations in a relational graph. CompGCN leverages a variety of entity-relation composition operations from Knowledge Graph Embedding techniques and scales with the number of relations. It also generalizes several of the existing multi-relational GCN methods. We evaluate our proposed method on multiple tasks such as node classification, link prediction, and graph classification, and achieve demonstrably superior results. We make the source code of CompGCN available to foster reproducible research."
            },
            {
                "source": "dblp",
                "title": "A Re-evaluation of Knowledge Graph Completion Methods.",
                "year": 2019,
                "authors": [
                    "Zhiqing Sun",
                    "Shikhar Vashishth",
                    "Soumya Sanyal 0001",
                    "Partha P. Talukdar",
                    "Yiming Yang"
                ],
                "link": "http://arxiv.org/abs/1911.03903",
                "abstract": "Knowledge Graph Completion (KGC) aims at automatically predicting missing links for large-scale knowledge graphs. A vast number of state-of-the-art KGC techniques have got published at top conferences in several research fields, including data mining, machine learning, and natural language processing. However, we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods. In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem. The proposed protocol is robust to handle bias in the model, which can substantially affect the final results. We conduct extensive experiments and report the performance of several existing methods using our protocol. The reproducible code has been made publicly available"
            },
            {
                "source": "dblp",
                "title": "Improving Document Classification with Multi-Sense Embeddings.",
                "year": 2019,
                "authors": [
                    "Vivek Gupta 0001",
                    "Ankit Kumar",
                    "Pegah Nokhiz",
                    "Harshit Gupta",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1911.07918",
                "abstract": "Efficient representation of text documents is an important building block in many NLP tasks. Research on long text categorization has shown that simple weighted averaging of word vectors for sentence representation often outperforms more sophisticated neural models. Recently proposed Sparse Composite Document Vector (SCDV) (Mekala et. al, 2017) extends this approach from sentences to documents using soft clustering over word vectors. However, SCDV disregards the multi-sense nature of words, and it also suffers from the curse of higher dimensionality. In this work, we address these shortcomings and propose SCDV-MS. SCDV-MS utilizes multi-sense word embeddings and learns a lower dimensional manifold. Through extensive experiments on multiple real-world datasets, we show that SCDV-MS embeddings outperform previous state-of-the-art embeddings on multi-class and multi-label text categorization tasks. Furthermore, SCDV-MS embeddings are more efficient than SCDV in terms of time and space complexity on textual classification tasks."
            },
            {
                "source": "dblp",
                "title": "ASAP: Adaptive Structure Aware Pooling for Learning Hierarchical Graph Representations.",
                "year": 2019,
                "authors": [
                    "Ekagra Ranjan",
                    "Soumya Sanyal 0001",
                    "Partha Pratim Talukdar"
                ],
                "link": "http://arxiv.org/abs/1911.07979",
                "abstract": "Graph Neural Networks (GNN) have been shown to work effectively for modeling graph structured data to solve tasks such as node classification, link prediction and graph classification. There has been some recent progress in defining the notion of pooling in graphs whereby the model tries to generate a graph level representation by downsampling and summarizing the information present in the nodes. Existing pooling methods either fail to effectively capture the graph substructure or do not easily scale to large graphs. In this work, we propose ASAP (Adaptive Structure Aware Pooling), a sparse and differentiable pooling method that addresses the limitations of previous graph pooling architectures. ASAP utilizes a novel self-attention network along with a modified GNN formulation to capture the importance of each node in a given graph. It also learns a sparse soft cluster assignment for nodes at each layer to effectively pool the subgraphs to form the pooled graph. Through extensive experiments on multiple datasets and theoretical analysis, we motivate our choice of the components used in ASAP. Our experimental results show that combining existing GNN architectures with ASAP leads to state-of-the-art results on multiple graph classification benchmarks. ASAP has an average improvement of 4%, compared to current sparse hierarchical state-of-the-art method."
            },
            {
                "source": "dblp",
                "title": "Never-ending learning.",
                "year": 2018,
                "authors": [
                    "Tom M. Mitchell",
                    "William W. Cohen",
                    "Estevam R. Hruschka Jr.",
                    "Partha P. Talukdar",
                    "Bo Yang 0011",
                    "Justin Betteridge",
                    "Andrew Carlson",
                    "Bhavana Dalvi Mishra",
                    "Matt Gardner 0001",
                    "Bryan Kisiel",
                    "Jayant Krishnamurthy",
                    "Ni Lao",
                    "Kathryn Mazaitis",
                    "Thahir Mohamed",
                    "Ndapandula Nakashole",
                    "Emmanouil A. Platanios",
                    "Alan Ritter",
                    "Mehdi Samadi",
                    "Burr Settles",
                    "Richard C. Wang",
                    "Derry Wijaya",
                    "Abhinav Gupta 0001",
                    "Xinlei Chen",
                    "Abulhair Saparov",
                    "Malcolm Greaves",
                    "Joel Welling"
                ],
                "link": "https://doi.org/10.1145/3191513",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Inductive Framework for Multi-Aspect Streaming Tensor Completion with Side Information.",
                "year": 2018,
                "authors": [
                    "Madhav Nimishakavi",
                    "Bamdev Mishra",
                    "Manish Gupta 0001",
                    "Partha Pratim Talukdar"
                ],
                "link": "http://arxiv.org/abs/1802.06371",
                "abstract": "Low rank tensor completion is a well studied problem and has applications in various fields. However, in many real world applications the data is dynamic, i.e., new data arrives at different time intervals. As a result, the tensors used to represent the data grow in size. Besides the tensors, in many real world scenarios, side information is also available in the form of matrices which also grow in size with time. The problem of predicting missing values in the dynamically growing tensor is called dynamic tensor completion. Most of the previous work in dynamic tensor completion make an assumption that the tensor grows only in one mode. To the best of our Knowledge, there is no previous work which incorporates side information with dynamic tensor completion. We bridge this gap in this paper by proposing a dynamic tensor completion framework called Side Information infused Incremental Tensor Analysis (SIITA), which incorporates side information and works for general incremental tensors. We also show how non-negative constraints can be incorporated with SIITA, which is essential for mining interpretable latent clusters. We carry out extensive experiments on multiple real world datasets to demonstrate the effectiveness of SIITA in various different settings."
            },
            {
                "source": "dblp",
                "title": "Improving Distantly Supervised Relation Extraction using Word and Entity Based Attention.",
                "year": 2018,
                "authors": [
                    "Sharmistha Jat",
                    "Siddhesh Khandelwal",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1804.06987",
                "abstract": "Relation extraction is the problem of classifying the relationship between two entities in a given sentence. Distant Supervision (DS) is a popular technique for developing relation extractors starting with limited supervision. We note that most of the sentences in the distant supervision relation extraction setting are very long and may benefit from word attention for better sentence representation. Our contributions in this paper are threefold. Firstly, we propose two novel word attention models for distantly- supervised relation extraction: (1) a Bi-directional Gated Recurrent Unit (Bi-GRU) based word attention model (BGWA), (2) an entity-centric attention model (EA), and (3) a combination model which combines multiple complementary models using weighted voting method for improved relation extraction. Secondly, we introduce GDS, a new distant supervision dataset for relation extraction. GDS removes test data noise present in all previous distant- supervision benchmark datasets, making credible automatic evaluation possible. Thirdly, through extensive experiments on multiple real-world datasets, we demonstrate the effectiveness of the proposed methods."
            },
            {
                "source": "dblp",
                "title": "Lovasz Convolutional Networks.",
                "year": 2018,
                "authors": [
                    "Prateek Yadav",
                    "Madhav Nimishakavi",
                    "Naganand Yadati",
                    "Arun Rajkumar",
                    "Partha Pratim Talukdar"
                ],
                "link": "http://arxiv.org/abs/1805.11365",
                "abstract": "Semi-supervised learning on graph structured data has received significant attention with the recent introduction of Graph Convolution Networks (GCN). While traditional methods have focused on optimizing a loss augmented with Laplacian regularization framework, GCNs perform an implicit Laplacian type regularization to capture local graph structure. In this work, we propose Lovasz Convolutional Network (LCNs) which are capable of incorporating global graph properties. LCNs achieve this by utilizing Lovasz's orthonormal embeddings of the nodes. We analyse local and global properties of graphs and demonstrate settings where LCNs tend to work better than GCNs. We validate the proposed method on standard random graph models such as stochastic block models (SBM) and certain community structure based graphs where LCNs outperform GCNs and learn more intuitive embeddings. We also perform extensive binary and multi-class classification experiments on real world datasets to demonstrate LCN's effectiveness. In addition to simple graphs, we also demonstrate the use of LCNs on hyper-graphs by identifying settings where they are expected to work better than GCNs."
            },
            {
                "source": "dblp",
                "title": "HyperGCN: Hypergraph Convolutional Networks for Semi-Supervised Classification.",
                "year": 2018,
                "authors": [
                    "Naganand Yadati",
                    "Madhav Nimishakavi",
                    "Prateek Yadav",
                    "Anand Louis",
                    "Partha Pratim Talukdar"
                ],
                "link": "http://arxiv.org/abs/1809.02589",
                "abstract": "In many real-world network datasets such as co-authorship, co-citation, email communication, etc., relationships are complex and go beyond pairwise. Hypergraphs provide a flexible and natural modeling tool to model such complex relationships. The obvious existence of such complex relationships in many real-world networks naturaly motivates the problem of learning with hypergraphs. A popular learning paradigm is hypergraph-based semi-supervised learning (SSL) where the goal is to assign labels to initially unlabeled vertices in a hypergraph. Motivated by the fact that a graph convolutional network (GCN) has been effective for graph-based SSL, we propose HyperGCN, a novel GCN for SSL on attributed hypergraphs. Additionally, we show how HyperGCN can be used as a learning-based approach for combinatorial optimisation on NP-hard hypergraph problems. We demonstrate HyperGCN's effectiveness through detailed experimentation on real-world hypergraphs."
            },
            {
                "source": "dblp",
                "title": "Graph Convolutional Networks based Word Embeddings.",
                "year": 2018,
                "authors": [
                    "Shikhar Vashishth",
                    "Prateek Yadav",
                    "Manik Bhandari",
                    "Piyush Rai",
                    "Chiranjib Bhattacharyya",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1809.04283",
                "abstract": "Word embeddings have been widely adopted across several NLP applications. Most existing word embedding methods utilize sequential context of a word to learn its embedding. While there have been some attempts at utilizing syntactic context of a word, such methods result in an explosion of the vocabulary size. In this paper, we overcome this problem by proposing SynGCN, a flexible Graph Convolution based method for learning word embeddings. SynGCN utilizes the dependency context of a word without increasing the vocabulary size. Word embeddings learned by SynGCN outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo. We also propose SemGCN, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations. We make the source code of both models available to encourage reproducible research."
            },
            {
                "source": "dblp",
                "title": "MT-CGCNN: Integrating Crystal Graph Convolutional Neural Network with Multitask Learning for Material Property Prediction.",
                "year": 2018,
                "authors": [
                    "Soumya Sanyal 0001",
                    "Janakiraman Balachandran",
                    "Naganand Yadati",
                    "Abhishek Kumar",
                    "Padmini Rajagopalan",
                    "Suchismita Sanyal",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1811.05660",
                "abstract": "Developing accurate, transferable and computationally inexpensive machine learning models can rapidly accelerate the discovery and development of new materials. Some of the major challenges involved in developing such models are, (i) limited availability of materials data as compared to other fields, (ii) lack of universal descriptor of materials to predict its various properties. The limited availability of materials data can be addressed through transfer learning, while the generic representation was recently addressed by Xie and Grossman [1], where they developed a crystal graph convolutional neural network (CGCNN) that provides a unified representation of crystals. In this work, we develop a new model (MT-CGCNN) by integrating CGCNN with transfer learning based on multi-task (MT) learning. We demonstrate the effectiveness of MT-CGCNN by simultaneous prediction of various material properties such as Formation Energy, Band Gap and Fermi Energy for a wide range of inorganic crystals (46774 materials). MT-CGCNN is able to reduce the test error when employed on correlated properties by upto 8%. The model prediction has lower test error compared to CGCNN, even when the training data is reduced by 10%. We also demonstrate our model's better performance through prediction of end user scenario related to metal/non-metal classification. These results encourage further development of machine learning approaches which leverage multi-task learning to address the aforementioned challenges in the discovery of new materials. We make MT-CGCNN's source code available to encourage reproducible research."
            },
            {
                "source": "dblp",
                "title": "RESIDE: Improving Distantly-Supervised Neural Relation Extraction using Side Information.",
                "year": 2018,
                "authors": [
                    "Shikhar Vashishth",
                    "Rishabh Joshi",
                    "Sai Suman Prayaga",
                    "Chiranjib Bhattacharyya",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1812.04361",
                "abstract": "Distantly-supervised Relation Extraction (RE) methods train an extractor by automatically aligning relation instances in a Knowledge Base (KB) with unstructured text. In addition to relation instances, KBs often contain other relevant side information, such as aliases of relations (e.g., founded and co-founded are aliases for the relation founderOfCompany). RE models usually ignore such readily available side information. In this paper, we propose RESIDE, a distantly-supervised neural relation extraction method which utilizes additional side information from KBs for improved relation extraction. It uses entity type and relation alias information for imposing soft constraints while predicting relations. RESIDE employs Graph Convolution Networks (GCN) to encode syntactic information from text and improves performance even when limited side information is available. Through extensive experiments on benchmark datasets, we demonstrate RESIDE's effectiveness. We have made RESIDE's source code available to encourage reproducible research."
            },
            {
                "source": "dblp",
                "title": "Event Schema Induction using Tensor Factorization with Back-off.",
                "year": 2017,
                "authors": [
                    "Madhav Nimishakavi",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1707.01917",
                "abstract": "Relation Schema Induction (RSI) is the problem of identifying type signatures of arguments of relations from unlabeled text. Most of the previous work in this area have focused only on binary RSI, i.e., inducing only the subject and object type signatures per relation. However, in practice, many relations are high-order, i.e., they have more than two arguments and inducing type signatures of all arguments is necessary. For example, in the sports domain, inducing a schema win(WinningPlayer, OpponentPlayer, Tournament, Location) is more informative than inducing just win(WinningPlayer, OpponentPlayer). We refer to this problem as Higher-order Relation Schema Induction (HRSI). In this paper, we propose Tensor Factorization with Back-off and Aggregation (TFBA), a novel framework for the HRSI problem. To the best of our knowledge, this is the first attempt at inducing higher-order relation schemata from unlabeled text. Using the experimental analysis on three real world datasets, we show how TFBA helps in dealing with sparsity and induce higher order schemata."
            },
            {
                "source": "dblp",
                "title": "CANDiS: Coupled & Attention-Driven Neural Distant Supervision.",
                "year": 2017,
                "authors": [
                    "Tushar Nagarajan",
                    "Sharmistha Jat",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1710.09942",
                "abstract": "Distant Supervision for Relation Extraction uses heuristically aligned text data with an existing knowledge base as training data. The unsupervised nature of this technique allows it to scale to web-scale relation extraction tasks, at the expense of noise in the training data. Previous work has explored relationships among instances of the same entity-pair to reduce this noise, but relationships among instances across entity-pairs have not been fully exploited. We explore the use of inter-instance couplings based on verb-phrase and entity type similarities. We propose a novel technique, CANDiS, which casts distant supervision using inter-instance coupling into an end-to-end neural network model. CANDiS incorporates an attention module at the instance-level to model the multi-instance nature of this problem. CANDiS outperforms existing state-of-the-art techniques on a standard benchmark dataset."
            },
            {
                "source": "dblp",
                "title": "Revisiting Simple Neural Networks for Learning Representations of Knowledge Graphs.",
                "year": 2017,
                "authors": [
                    "Srinivas Ravishankar",
                    "Chandrahas",
                    "Partha Pratim Talukdar"
                ],
                "link": "http://arxiv.org/abs/1711.05401",
                "abstract": "We address the problem of learning vector representations for entities and relations in Knowledge Graphs (KGs) for Knowledge Base Completion (KBC). This problem has received significant attention in the past few years and multiple methods have been proposed. Most of the existing methods in the literature use a predefined characteristic scoring function for evaluating the correctness of KG triples. These scoring functions distinguish correct triples (high score) from incorrect ones (low score). However, their performance vary across different datasets. In this work, we demonstrate that a simple neural network based score function can consistently achieve near start-of-the-art performance on multiple datasets. We also quantitatively demonstrate biases in standard benchmark datasets, and highlight the need to perform evaluation spanning various datasets."
            },
            {
                "source": "dblp",
                "title": "Inducing Interpretability in Knowledge Graph Embeddings.",
                "year": 2017,
                "authors": [
                    "Chandrahas",
                    "Tathagata Sengupta",
                    "Cibi Pragadeesh",
                    "Partha Pratim Talukdar"
                ],
                "link": "http://arxiv.org/abs/1712.03547",
                "abstract": "We study the problem of inducing interpretability in KG embeddings. Specifically, we explore the Universal Schema (Riedel et al., 2013) and propose a method to induce interpretability. There have been many vector space models proposed for the problem, however, most of these methods don't address the interpretability (semantics) of individual dimensions. In this work, we study this problem and propose a method for inducing interpretability in KG embeddings using entity co-occurrence statistics. The proposed method significantly improves the interpretability, while maintaining comparable performance in other KG tasks."
            },
            {
                "source": "dblp",
                "title": "Turbo-SMT: Parallel coupled sparse matrix-Tensor factorizations and applications.",
                "year": 2016,
                "authors": [
                    "Evangelos E. Papalexakis",
                    "Tom M. Mitchell",
                    "Nicholas D. Sidiropoulos",
                    "Christos Faloutsos",
                    "Partha Pratim Talukdar",
                    "Brian Murphy"
                ],
                "link": "https://doi.org/10.1002/sam.11315",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Relation Schema Induction using Tensor Factorization with Side Information.",
                "year": 2016,
                "authors": [
                    "Madhav Nimishakavi",
                    "Uday Singh Saini",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1605.04227",
                "abstract": "Given a set of documents from a specific domain (e.g., medical research journals), how do we automatically build a Knowledge Graph (KG) for that domain? Automatic identification of relations and their schemas, i.e., type signature of arguments of relations (e.g., undergo(Patient, Surgery)), is an important first step towards this goal. We refer to this problem as Relation Schema Induction (RSI). In this paper, we propose Schema Induction using Coupled Tensor Factorization (SICTF), a novel tensor factorization method for relation schema induction. SICTF factorizes Open Information Extraction (OpenIE) triples extracted from a domain corpus along with additional side information in a principled way to induce relation schemas. To the best of our knowledge, this is the first application of tensor factorization for the RSI problem. Through extensive experiments on multiple real-world datasets, we find that SICTF is not only more accurate than state-of-the-art baselines, but also significantly faster (about 14x faster)."
            },
            {
                "source": "dblp",
                "title": "Relational Crowdsourcing and its Application in Knowledge Graph Evaluation.",
                "year": 2016,
                "authors": [
                    "Prakhar Ojha",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1610.06912",
                "abstract": "Automatic construction of large knowledge graphs (KG) by mining web-scale text datasets has received considerable attention recently. Estimating accuracy of such automatically constructed KGs is a challenging problem due to their size and diversity. This important problem has largely been ignored in prior research we fill this gap and propose KGEval. KGEval binds facts of a KG using coupling constraints and crowdsources the facts that infer correctness of large parts of the KG. We demonstrate that the objective optimized by KGEval is submodular and NP-hard, allowing guarantees for our approximation algorithm. Through extensive experiments on real-world datasets, we demonstrate that KGEval is able to estimate KG accuracy more accurately compared to other competitive baselines, while requiring significantly lesser number of human evaluations."
            },
            {
                "source": "dblp",
                "title": "Active learning in keyword search-based data integration.",
                "year": 2015,
                "authors": [
                    "Zhepeng Yan",
                    "Nan Zheng",
                    "Zachary G. Ives",
                    "Partha Pratim Talukdar",
                    "Cong Yu 0001"
                ],
                "link": "https://doi.org/10.1007/s00778-014-0374-x",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Seeing the Forest through the Trees: Adaptive Local Exploration of Large Graphs.",
                "year": 2015,
                "authors": [
                    "Robert S. Pienta",
                    "Zhiyuan Lin 0001",
                    "Minsuk Kahng",
                    "Jilles Vreeken",
                    "Partha P. Talukdar",
                    "James Abello",
                    "Ganesh Parameswaran",
                    "Duen Horng Chau"
                ],
                "link": "http://arxiv.org/abs/1505.06792",
                "abstract": "Visualization is a powerful paradigm for exploratory data analysis. Visualizing large graphs, however, often results in a meaningless hairball. In this paper, we propose a different approach that helps the user adaptively explore large million-node graphs from a local perspective. For nodes that the user investigates, we propose to only show the neighbors with the most subjectively interesting neighborhoods. We contribute novel ideas to measure this interestingness in terms of how surprising a neighborhood is given the background distribution, as well as how well it fits the nodes the user chose to explore. We introduce FACETS, a fast and scalable method for visually exploring large graphs. By implementing our above ideas, it allows users to look into the forest through its trees. Empirical evaluation shows that our method works very well in practice, providing rankings of nodes that match interests of users. Moreover, as it scales linearly, FACETS is suited for the exploration of very large graphs."
            },
            {
                "source": "dblp",
                "title": "Want Answers? A Reddit Inspired Study on How to Pose Questions.",
                "year": 2015,
                "authors": [
                    "Danish",
                    "Yogesh Dahiya",
                    "Partha P. Talukdar"
                ],
                "link": "http://arxiv.org/abs/1512.01768",
                "abstract": "Questions form an integral part of our everyday communication, both offline and online. Getting responses to our questions from others is fundamental to satisfying our information need and in extending our knowledge boundaries. A question may be represented using various factors such as social, syntactic, semantic, etc. We hypothesize that these factors contribute with varying degrees towards getting responses from others for a given question. We perform a thorough empirical study to measure effects of these factors using a novel question and answer dataset from the website this http URL. To the best of our knowledge, this is the first such analysis of its kind on this important topic. We also use a sparse nonnegative matrix factorization technique to automatically induce interpretable semantic factors from the question dataset. We also document various patterns on response prediction we observe during our analysis in the data. For instance, we found that preference-probing questions are scantily answered. Our method is robust to capture such latent response factors. We hope to make our code and datasets publicly available upon publication of the paper."
            },
            {
                "source": "dblp",
                "title": "Good-Enough Brain Model: Challenges, Algorithms, and Discoveries in Multisubject Experiments.",
                "year": 2014,
                "authors": [
                    "Evangelos E. Papalexakis",
                    "Alona Fyshe",
                    "Nicholas D. Sidiropoulos",
                    "Partha Pratim Talukdar",
                    "Tom M. Mitchell",
                    "Christos Faloutsos"
                ],
                "link": "https://doi.org/10.1089/big.2014.0044",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Actively Soliciting Feedback for Query Answers in Keyword Search-Based Data Integration.",
                "year": 2013,
                "authors": [
                    "Zhepeng Yan",
                    "Nan Zheng",
                    "Zachary G. Ives",
                    "Partha Pratim Talukdar",
                    "Cong Yu 0001"
                ],
                "link": "http://www.vldb.org/pvldb/vol6/p205-ives.pdf",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "Scoup-SMT: Scalable Coupled Sparse Matrix-Tensor Factorization",
                "year": 2013,
                "authors": [
                    "Evangelos E. Papalexakis",
                    "Tom M. Mitchell",
                    "Nicholas D. Sidiropoulos",
                    "Christos Faloutsos",
                    "Partha Pratim Talukdar",
                    "Brian Murphy"
                ],
                "link": "http://arxiv.org/abs/1302.7043",
                "abstract": "How can we correlate neural activity in the human brain as it responds to words, with behavioral data expressed as answers to questions about these same words? In short, we want to find latent variables, that explain both the brain activity, as well as the behavioral responses. We show that this is an instance of the Coupled Matrix-Tensor Factorization (CMTF) problem. We propose Scoup-SMT, a novel, fast, and parallel algorithm that solves the CMTF problem and produces a sparse latent low-rank subspace of the data. In our experiments, we find that Scoup-SMT is 50-100 times faster than a state-of-the-art algorithm for CMTF, along with a 5 fold increase in sparsity. Moreover, we extend Scoup-SMT to handle missing data without degradation of performance. We apply Scoup-SMT to BrainQ, a dataset consisting of a (nouns, brain voxels, human subjects) tensor and a (nouns, properties) matrix, with coupling along the nouns dimension. Scoup-SMT is able to find meaningful latent variables, as well as to predict brain activity with competitive accuracy. Finally, we demonstrate the generality of Scoup-SMT, by applying it on a Facebook dataset (users, friends, wall-postings); there, Scoup-SMT spots spammer-like anomalies."
            },
            {
                "source": "dblp",
                "title": "Scaling Graph-based Semi Supervised Learning to Large Number of Labels Using Count-Min Sketch.",
                "year": 2013,
                "authors": [
                    "Partha Pratim Talukdar",
                    "William W. Cohen"
                ],
                "link": "http://arxiv.org/abs/1310.2959",
                "abstract": "Graph-based Semi-supervised learning (SSL) algorithms have been successfully used in a large number of applications. These methods classify initially unlabeled nodes by propagating label information over the structure of graph starting from seed nodes. Graph-based SSL algorithms usually scale linearly with the number of distinct labels (m), and require O(m) space on each node. Unfortunately, there exist many applications of practical significance with very large m over large graphs, demanding better space and time complexity. In this paper, we propose MAD-SKETCH, a novel graph-based SSL algorithm which compactly stores label distribution on each node using Count-min Sketch, a randomized data structure. We present theoretical analysis showing that under mild conditions, MAD-SKETCH can reduce space complexity at each node from O(m) to O(log m), and achieve similar savings in time complexity as well. We support our analysis through experiments on multiple real world datasets. We observe that MAD-SKETCH achieves similar performance as existing state-of-the-art graph- based SSL algorithms, while requiring smaller memory footprint and at the same time achieving up to 10x speedup. We find that MAD-SKETCH is able to scale to datasets with one million labels, which is beyond the scope of existing graph- based SSL algorithms."
            },
            {
                "source": "dblp",
                "title": "Interactive Data Integration through Smart Copy & Paste",
                "year": 2009,
                "authors": [
                    "Zachary G. Ives",
                    "Craig A. Knoblock",
                    "Steven Minton",
                    "Marie Jacob",
                    "Partha Pratim Talukdar",
                    "Rattapoom Tuchinda",
                    "Jos Luis Ambite",
                    "Maria Muslea",
                    "Cenk Gazen"
                ],
                "link": "http://arxiv.org/abs/0909.1769",
                "abstract": "In many scenarios, such as emergency response or ad hoc collaboration, it is critical to reduce the overhead in integrating data. Ideally, one could perform the entire process interactively under one unified interface: defining extractors and wrappers for sources, creating a mediated schema, and adding schema mappings ? while seeing how these impact the integrated view of the data, and refining the design accordingly.We propose a novel smart copy and paste (SCP) model and architecture for seamlessly combining the design-time and run-time aspects of data integration, and we describe an initial prototype, the CopyCat system. In CopyCat, the user does not need special tools for the different stages of integration: instead, the system watches as the user copies data from applications (including the Web browser) and pastes them into CopyCat?s spreadsheet-like workspace. CopyCat generalizes these actions and presents proposed auto-completions, each with an explanation in the form of provenance. The user provides feedback on these suggestions ? through either direct interactions or further copy-and-paste operations ? and the system learns from this feedback. This paper provides an overview of our prototype system, and identifies key research challenges in achieving SCP in its full generality.     Comments:CIDR 2009Subjects:Databases (cs.DB); Artificial Intelligence (cs.AI)Cite as:arXiv:0909.1769 [cs.DB](or arXiv:0909.1769v1 [cs.DB] for this version)           https://doi.org/10.48550/arXiv.0909.1769Focus to learn more                  arXiv-issued DOI via DataCite"
            },
            {
                "source": "dblp",
                "title": "Learning to create data-integrating queries.",
                "year": 2008,
                "authors": [
                    "Partha Pratim Talukdar",
                    "Marie Jacob",
                    "Muhammad Salman Mehmood",
                    "Koby Crammer",
                    "Zachary G. Ives",
                    "Fernando C. N. Pereira",
                    "Sudipto Guha"
                ],
                "link": "http://www.vldb.org/pvldb/vol1/1453941.pdf",
                "abstract": null
            },
            {
                "source": "dblp",
                "title": "The ORCHESTRA Collaborative Data Sharing System.",
                "year": 2008,
                "authors": [
                    "Zachary G. Ives",
                    "Todd J. Green",
                    "Grigoris Karvounarakis",
                    "Nicholas E. Taylor",
                    "Val Tannen",
                    "Partha Pratim Talukdar",
                    "Marie Jacob",
                    "Fernando C. N. Pereira"
                ],
                "link": "https://doi.org/10.1145/1462571.1462577",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Never-ending Learning",
                "year": 2018,
                "authors": [
                    "T Mitchell",
                    "W Cohen",
                    "E Hruschka",
                    "P Talukdar",
                    "B Yang",
                    "J Betteridge",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:a2necdfpwlEC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Never-Ending Learning",
                "year": 2015,
                "authors": [
                    "T Mitchell",
                    "W Cohen",
                    "E Hruschka Jr",
                    "P Talukdar",
                    "J Betteridge",
                    "A Carlson",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:as0KMg8qHbkC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Composition-based multi-relational graph convolutional networks",
                "year": 2019,
                "authors": [
                    "S Vashishth",
                    "S Sanyal",
                    "V Nitin",
                    "P Talukdar"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:WIXB4To3Tx4C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Improving multi-hop question answering over knowledge graphs using knowledge base embeddings",
                "year": 2020,
                "authors": [
                    "A Saxena",
                    "A Tripathi",
                    "P Talukdar"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:N6_Y7JlWxwsC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Hypergcn: A new method for training graph convolutional networks on hypergraphs",
                "year": 2019,
                "authors": [
                    "N Yadati",
                    "M Nimishakavi",
                    "P Yadav",
                    "V Nitin",
                    "A Louis",
                    "P Talukdar"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:gmHTDCtJMcoC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Hyte: Hyperplane-based temporally aware knowledge graph embedding",
                "year": 2018,
                "authors": [
                    "SS Dasgupta",
                    "SN Ray",
                    "P Talukdar"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:wuD5JclIwkYC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Interacte: Improving convolution-based knowledge graph embeddings by increasing feature interactions",
                "year": 2020,
                "authors": [
                    "S Vashishth",
                    "S Sanyal",
                    "V Nitin",
                    "N Agrawal",
                    "P Talukdar"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:8RAEygVn5_EC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Asap: Adaptive structure aware pooling for learning hierarchical graph representations",
                "year": 2020,
                "authors": [
                    "E Ranjan",
                    "S Sanyal",
                    "P Talukdar"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:C-Rn0OCouf8C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Simultaneously uncovering the patterns of brain regions involved in different story reading subprocesses",
                "year": 2014,
                "authors": [
                    "L Wehbe",
                    "B Murphy",
                    "P Talukdar",
                    "A Fyshe",
                    "A Ramdas",
                    "T Mitchell"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:Y9VhQm-5nPIC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "New regularized algorithms for transductive learning",
                "year": 2009,
                "authors": [
                    "PP Talukdar",
                    "K Crammer"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:eQOLeE2rZwMC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Reside: Improving distantly-supervised neural relation extraction using side information",
                "year": 2018,
                "authors": [
                    "S Vashishth",
                    "R Joshi",
                    "SS Prayaga",
                    "C Bhattacharyya",
                    "P Talukdar"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:G36d5HCDkJYC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Muril: Multilingual representations for indian languages",
                "year": 2021,
                "authors": [
                    "S Khanuja",
                    "D Bansal",
                    "S Mehtani",
                    "S Khosla",
                    "A Dey",
                    "B Gopalan",
                    "..."
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:GiYFt9mpioMC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Learning Effective and Interpretable Semantic Models using Non-Negative Sparse Embedding",
                "year": 2012,
                "authors": [
                    "B Murphy",
                    "P Talukdar",
                    "T Mitchell"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:ZeXyd9-uunAC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Incorporating vector space similarity in random walk inference over knowledge bases",
                "year": 2014,
                "authors": [
                    "M Gardner",
                    "P Talukdar",
                    "J Krishnamurthy",
                    "T Mitchell"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:g8uWPOAv7ggC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Kvqa: Knowledge-aware visual question answering",
                "year": 2019,
                "authors": [
                    "S Shah",
                    "A Mishra",
                    "N Yadati",
                    "PP Talukdar"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:wGzT3bKASkAC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Graph-based semi-supervised learning",
                "year": 2014,
                "authors": [
                    "A Subramanya",
                    "PP Talukdar"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:kUhpeDhEZMUC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "A re-evaluation of knowledge graph completion methods",
                "year": 2019,
                "authors": [
                    "Z Sun",
                    "S Vashishth",
                    "S Sanyal",
                    "P Talukdar",
                    "Y Yang"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:kO05sadLmrgC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "NILE: Natural Language Inference with Faithful Natural Language Explanations",
                "year": 2020,
                "authors": [
                    "S Kumar",
                    "P Talukdar"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:oldoQiaHq2UC",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Weakly-supervised acquisition of labeled class instances using graph random walks",
                "year": 2008,
                "authors": [
                    "P Talukdar",
                    "J Reisinger",
                    "M Pasca",
                    "D Ravichandran",
                    "R Bhagat",
                    "F Pereira"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:u5HHmVD_uO8C",
                "abstract": null
            },
            {
                "source": "scholar",
                "title": "Automatic code assignment to medical text",
                "year": 2007,
                "authors": [
                    "K Crammer",
                    "M Dredze",
                    "K Ganchev",
                    "P Talukdar",
                    "S Carroll"
                ],
                "link": "https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:zYLM7Y9cAGgC",
                "abstract": null
            }
        ],
        "info": {
            "name": "Partha Talukdar",
            "affiliations": "Google Research and IISc Bangalore",
            "email": "Verified email at iisc.ac.in",
            "website": "https://parthatalukdar.github.io/",
            "interests": [
                {
                    "title": "Natural Language Processing",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:natural_language_processing",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Anatural_language_processing"
                },
                {
                    "title": "Machine Learning",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:machine_learning",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Amachine_learning"
                },
                {
                    "title": "Multilingual learning",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:multilingual_learning",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Amultilingual_learning"
                },
                {
                    "title": "Knowledge Graphs",
                    "link": "https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:knowledge_graphs",
                    "serpapi_link": "https://serpapi.com/search.json?engine=google_scholar_profiles&hl=en&mauthors=label%3Aknowledge_graphs"
                }
            ],
            "thumbnail": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=CIZwXAcAAAAJ&citpid=3",
            "graph": [
                {
                    "year": 2008,
                    "citations": 43
                },
                {
                    "year": 2009,
                    "citations": 77
                },
                {
                    "year": 2010,
                    "citations": 102
                },
                {
                    "year": 2011,
                    "citations": 145
                },
                {
                    "year": 2012,
                    "citations": 163
                },
                {
                    "year": 2013,
                    "citations": 198
                },
                {
                    "year": 2014,
                    "citations": 234
                },
                {
                    "year": 2015,
                    "citations": 361
                },
                {
                    "year": 2016,
                    "citations": 376
                },
                {
                    "year": 2017,
                    "citations": 480
                },
                {
                    "year": 2018,
                    "citations": 567
                },
                {
                    "year": 2019,
                    "citations": 723
                },
                {
                    "year": 2020,
                    "citations": 957
                },
                {
                    "year": 2021,
                    "citations": 1408
                },
                {
                    "year": 2022,
                    "citations": 1915
                },
                {
                    "year": 2023,
                    "citations": 2162
                },
                {
                    "year": 2024,
                    "citations": 1721
                }
            ],
            "citations": {
                "all": 11881,
                "since_2019": 8900
            },
            "h_index": {
                "all": 51,
                "since_2019": 38
            },
            "i10_index": {
                "all": 109,
                "since_2019": 89
            }
        }
    }
}